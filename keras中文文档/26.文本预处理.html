<!DOCTYPE html>
    <html><head><meta charset="UTF-8">
    </head><body>
    <p><a href="http://keras-cn.readthedocs.io/en/latest/">原文链接</a></p>
        <div class="section">
<h1 id="_1">文本预处理</h1>
<h2 id="text_to_word_sequence">句子分割text_to_word_sequence</h2>
<pre><code class="python">keras.preprocessing.text.text_to_word_sequence(text,
                                               filters='!"#$%&amp;()*+,-./:;&lt;=&gt;?@[\]^_`{|}~\t\n',
                                               lower=True,
                                               split=" ")
</code></pre>
<p>本函数将一个句子拆分成单词构成的列表</p>
<h3 id="_2">参数</h3>
<ul>
<li>
<p>text：字符串，待处理的文本</p>
</li>
<li>
<p>filters：需要滤除的字符的列表或连接形成的字符串，例如标点符号。默认值为 '!"#$%&amp;()*+,-./:;&lt;=&gt;?@[]^_`{|}~\t\n'，包含标点符号，制表符和换行符等</p>
</li>
<li>
<p>lower：布尔值，是否将序列设为小写形式</p>
</li>
<li>
<p>split：字符串，单词的分隔符，如空格</p>
</li>
</ul>
<h3 id="_3">返回值</h3>
<p>字符串列表</p>
<hr/>
<h2 id="one-hot">one-hot编码</h2>
<pre><code class="python">keras.preprocessing.text.one_hot(text,
                                 n,
                                 filters='!"#$%&amp;()*+,-./:;&lt;=&gt;?@[\]^_`{|}~\t\n',
                                 lower=True,
                                 split=" ")
</code></pre>
<p>本函数将一段文本编码为one-hot形式的码，即仅记录词在词典中的下标。</p>
<p>【Tips】
从定义上，当字典长为n时，每个单词应形成一个长为n的向量，其中仅有单词本身在字典中下标的位置为1，其余均为0，这称为one-hot。</p>
<p>为了方便起见，函数在这里仅把“1”的位置，即字典中词的下标记录下来。</p>
<h3 id="_4">参数</h3>
<ul>
<li>n：整数，字典长度</li>
</ul>
<h3 id="_5">返回值</h3>
<p>整数列表，每个整数是[1,n]之间的值，代表一个单词（不保证唯一性，即如果词典长度不够，不同的单词可能会被编为同一个码）。</p>
<hr/>
<h2 id="hashing_trick">特征哈希hashing_trick</h2>
<pre><code class="python">keras.preprocessing.text.hashing_trick(text,
                                       n,
                                       hash_function=None,
                                       filters='!"#$%&amp;()*+,-./:;&lt;=&gt;?@[\]^_`{|}~\t\n',
                                       lower=True,
                                       split=' ')
</code></pre>
<p>将文本转换为固定大小的哈希空间中的索引序列</p>
<h3 id="_6">参数</h3>
<ul>
<li>
<p>n: 哈希空间的维度</p>
</li>
<li>
<p>hash_function: 默认为 python <code>hash</code> 函数, 可以是 'md5' 或任何接受输入字符串, 并返回 int 的函数. 注意 <code>hash</code> 不是一个稳定的哈希函数, 因此在不同执行环境下会产生不同的结果, 作为对比, 'md5' 是一个稳定的哈希函数.</p>
</li>
</ul>
<h3 id="_7">返回值</h3>
<p>整数列表</p>
<h2 id="tokenizer">分词器Tokenizer</h2>
<pre><code class="python">keras.preprocessing.text.Tokenizer(num_words=None,
                                   filters='!"#$%&amp;()*+,-./:;&lt;=&gt;?@[\]^_`{|}~\t\n',
                                   lower=True,
                                   split=" ",
                                   char_level=False)
</code></pre>
<p>Tokenizer是一个用于向量化文本，或将文本转换为序列（即单词在字典中的下标构成的列表，从1算起）的类。</p>
<h3 id="_8">构造参数</h3>
<ul>
<li>
<p>与<code>text_to_word_sequence</code>同名参数含义相同</p>
</li>
<li>
<p>num_words：None或整数，处理的最大单词数量。若被设置为整数，则分词器将被限制为待处理数据集中最常见的<code>num_words</code>个单词</p>
</li>
<li>
<p>char_level: 如果为 True, 每个字符将被视为一个标记</p>
</li>
</ul>
<h3 id="_9">类方法</h3>
<ul>
<li>
<p>fit_on_texts(texts)</p>
<ul>
<li>texts：要用以训练的文本列表</li>
</ul>
</li>
<li>
<p>texts_to_sequences(texts)</p>
<ul>
<li>
<p>texts：待转为序列的文本列表</p>
</li>
<li>
<p>返回值：序列的列表，列表中每个序列对应于一段输入文本</p>
</li>
</ul>
</li>
<li>
<p>texts_to_sequences_generator(texts)</p>
<ul>
<li>
<p>本函数是<code>texts_to_sequences</code>的生成器函数版</p>
</li>
<li>
<p>texts：待转为序列的文本列表</p>
</li>
<li>
<p>返回值：每次调用返回对应于一段输入文本的序列</p>
</li>
</ul>
</li>
<li>
<p>texts_to_matrix(texts, mode)：</p>
<ul>
<li>
<p>texts：待向量化的文本列表</p>
</li>
<li>
<p>mode：‘binary’，‘count’，‘tfidf’，‘freq’之一，默认为‘binary’</p>
</li>
<li>
<p>返回值：形如<code>(len(texts), nb_words)</code>的numpy array</p>
</li>
</ul>
</li>
<li>
<p>fit_on_sequences(sequences):</p>
<ul>
<li>sequences：要用以训练的序列列表</li>
</ul>
</li>
<li>
<p>sequences_to_matrix(sequences):</p>
<ul>
<li>
<p>sequences：待向量化的序列列表</p>
</li>
<li>
<p>mode：‘binary’，‘count’，‘tfidf’，‘freq’之一，默认为‘binary’</p>
</li>
<li>
<p>返回值：形如<code>(len(sequences), nb_words)</code>的numpy array</p>
</li>
</ul>
</li>
</ul>
<h3 id="_10">属性</h3>
<ul>
<li>word_counts:字典，将单词（字符串）映射为它们在训练期间出现的次数。仅在调用fit_on_texts之后设置。</li>
<li>word_docs: 字典，将单词（字符串）映射为它们在训练期间所出现的文档或文本的数量。仅在调用fit_on_texts之后设置。</li>
<li>word_index: 字典，将单词（字符串）映射为它们的排名或者索引。仅在调用fit_on_texts之后设置。</li>
<li>document_count: 整数。分词器被训练的文档（文本或者序列）数量。仅在调用fit_on_texts或fit_on_sequences之后设置。</li>
</ul>
</div>
    </body></html>