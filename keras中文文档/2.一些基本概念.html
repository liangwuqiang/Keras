<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8"/>
	<title></title>
	<meta name="generator" content="LibreOffice 5.1.4.2 (Linux)"/>
	<meta name="created" content="00:00:00"/>
	<meta name="changed" content="2017-09-17T15:28:06.169820658"/>
	<meta name="" content=""/>
	<style type="text/css">
		pre.ctl { font-family: "Liberation Mono", monospace }
		code.ctl { font-family: "Liberation Mono", monospace }
	</style>
</head>
<body lang="zh-CN" dir="ltr">
<p><a href="http://keras-cn.readthedocs.io/en/latest/"><span style="background: #ffff00">原文链接</span></a></p>
<h1><a name="_1"></a><span style="background: #ffff00">一些基本概念</span></h1>
<p><span style="background: #ffff00">在开始学习<font face="Liberation Serif, serif"><span lang="en-US">Keras</span></font>之前，我们希望传递一些关于<font face="Liberation Serif, serif"><span lang="en-US">Keras</span></font>，关于深度学习的基本概念和技术，我们建议新手在使用<font face="Liberation Serif, serif"><span lang="en-US">Keras</span></font>之前浏览一下本页面提到的内容，这将减少你学习中的困惑</span></p>
<h2><a name="_2"></a><span style="background: #ffff00">符号计算</span></h2>
<p><font face="Liberation Serif, serif"><span lang="en-US"><span style="background: #ffff00">Keras</span></font>的底层库使用<font face="Liberation Serif, serif"><span lang="en-US">Theano</span></font>或<font face="Liberation Serif, serif"><span lang="en-US">TensorFlow</span></font>，这两个库也称为<font face="Liberation Serif, serif"><span lang="en-US">Keras</span></font>的后端。无论是<font face="Liberation Serif, serif"><span lang="en-US">Theano</span></font>还是<font face="Liberation Serif, serif"><span lang="en-US">TensorFlow</span></font>，都是一个“符号式”的库。</span></p>
<p><span style="background: #ffff00">因此，这也使得<font face="Liberation Serif, serif"><span lang="en-US">Keras</span></font>的编程与传统的<font face="Liberation Serif, serif"><span lang="en-US">Python</span></font>代码有所差别。笼统的说，符号主义的计算首先定义各种变量，然后建立一个“计算图”，计算图规定了各个变量之间的计算关系。建立好的计算图需要编译以确定其内部细节，然而，此时的计算图还是一个“空壳子”，里面没有任何实际的数据，只有当你把需要运算的输入放进去后，才能在整个模型中形成数据流，从而形成输出值。</span></p>
<p><span style="background: #ffff00">就像用管道搭建供水系统，当你在拼水管的时候，里面是没有水的。只有所有的管子都接完了，才能送水。</span></p>
<p><font face="Liberation Serif, serif"><span lang="en-US"><span style="background: #ffff00">Keras</span></font>的模型搭建形式就是这种方法，在你搭建<font face="Liberation Serif, serif"><span lang="en-US">Keras</span></font>模型完毕后，你的模型就是一个空壳子，只有实际生成可调用的函数后（<font face="Liberation Serif, serif"><span lang="en-US">K.function</span></font>），输入数据，才会形成真正的数据流。</span></p>
<p><span style="background: #ffff00">使用计算图的语言，如<font face="Liberation Serif, serif"><span lang="en-US">Theano</span></font>，以难以调试而闻名，当<font face="Liberation Serif, serif"><span lang="en-US">Keras</span></font>的<font face="Liberation Serif, serif"><span lang="en-US">Debug</span></font>进入<font face="Liberation Serif, serif"><span lang="en-US">Theano</span></font>这个层次时，往往也令人头痛。没有经验的开发者很难直观的感受到计算图到底在干些什么。尽管很让人头痛，但大多数的深度学习框架使用的都是符号计算这一套方法，因为符号计算能够提供关键的计算优化、自动求导等功能。</span></p>
<p><span style="background: #ffff00">我们建议你在使用前稍微了解一下<font face="Liberation Serif, serif"><span lang="en-US">Theano</span></font>或<font face="Liberation Serif, serif"><span lang="en-US">TensorFlow</span></font>，<font face="Liberation Serif, serif"><span lang="en-US">Bing/Google</span></font>一下即可。</span></p>
<h2><a name="_3"></a><span style="background: #ffff00">张量</span></h2>
<p><span style="background: #ffff00">张量，或<font face="Liberation Serif, serif"><span lang="en-US">tensor</span></font>，是本文档会经常出现的一个词汇，在此稍作解释。</span></p>
<p><span style="background: #ffff00">使用这个词汇的目的是为了表述统一，张量可以看作是向量、矩阵的自然推广，我们用张量来表示广泛的数据类型。</span></p>
<p><span style="background: #ffff00">规模最小的张量是<font face="Liberation Serif, serif"><span lang="en-US">0</span></font>阶张量，即标量，也就是一个数。</span></p>
<p><span style="background: #ffff00">当我们把一些数有序的排列起来，就形成了<font face="Liberation Serif, serif"><span lang="en-US">1</span></font>阶张量，也就是一个向量</span></p>
<p><span style="background: #ffff00">如果我们继续把一组向量有序的排列起来，就形成了<font face="Liberation Serif, serif"><span lang="en-US">2</span></font>阶张量，也就是一个矩阵</span></p>
<p><span style="background: #ffff00">把矩阵摞起来，就是<font face="Liberation Serif, serif"><span lang="en-US">3</span></font>阶张量，我们可以称为一个立方体，具有<font face="Liberation Serif, serif"><span lang="en-US">3</span></font>个颜色通道的彩色图片就是一个这样的立方体</span></p>
<p><span style="background: #ffff00">把立方体摞起来，好吧这次我们真的没有给它起别名了，就叫<font face="Liberation Serif, serif"><span lang="en-US">4</span></font>阶张量了，不要去试图想像<font face="Liberation Serif, serif"><span lang="en-US">4</span></font>阶张量是什么样子，它就是个数学上的概念。</span></p>
<p><span style="background: #ffff00">张量的阶数有时候也称为维度，或者轴，轴这个词翻译自英文<font face="Liberation Serif, serif"><span lang="en-US">axis</span></font>。譬如一个矩阵<font face="Liberation Serif, serif"><span lang="en-US">[[1,2],[3,4]]</span></font>，是一个<font face="Liberation Serif, serif"><span lang="en-US">2</span></font>阶张量，有两个维度或轴，沿着第<font face="Liberation Serif, serif"><span lang="en-US">0</span></font>个轴（为了与<font face="Liberation Serif, serif"><span lang="en-US">python</span></font>的计数方式一致，本文档维度和轴从<font face="Liberation Serif, serif"><span lang="en-US">0</span></font>算起）你看到的是<font face="Liberation Serif, serif"><span lang="en-US">[1,2]</span></font>，<font face="Liberation Serif, serif"><span lang="en-US">[3,4]</span></font>两个向量，沿着第<font face="Liberation Serif, serif"><span lang="en-US">1</span></font>个轴你看到的是<font face="Liberation Serif, serif"><span lang="en-US">[1,3]</span></font>，<font face="Liberation Serif, serif"><span lang="en-US">[2,4]</span></font>两个向量。</span></p>
<p><span style="background: #ffff00">要理解“沿着某个轴”是什么意思，不妨试着运行一下下面的代码：</span></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">import numpy as np</span></code></span></font>

<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">a = np.array([[1,2],[3,4]])</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">sum0 = np.sum(a, axis=0)</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">sum1 = np.sum(a, axis=1)</span></code></span></font>

<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">print sum0</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">print sum1</span></code></span></font></pre><p>
<span style="background: #ffff00">关于张量，目前知道这么多就足够了。事实上我也就知道这么多</span></p>
<h2><a name="data_format"></a><font face="Liberation Serif, serif"><span lang="en-US"><span style="background: #ffff00">data_format</span></span></font></h2>
<p><span style="background: #ffff00">这是一个无可奈何的问题，在如何表示一组彩色图片的问题上，<font face="Liberation Serif, serif"><span lang="en-US">Theano</span></font>和<font face="Liberation Serif, serif"><span lang="en-US">TensorFlow</span></font>发生了分歧，<font face="Liberation Serif, serif"><span lang="en-US">'th'</span></font>模式，也即<font face="Liberation Serif, serif"><span lang="en-US">Theano</span></font>模式会把<font face="Liberation Serif, serif"><span lang="en-US">100</span></font>张<font face="Liberation Serif, serif"><span lang="en-US">RGB</span></font>三通道的<font face="Liberation Serif, serif"><span lang="en-US">16×32</span></font>（高为<font face="Liberation Serif, serif"><span lang="en-US">16</span></font>宽为<font face="Liberation Serif, serif"><span lang="en-US">32</span></font>）彩色图表示为下面这种形式（<font face="Liberation Serif, serif"><span lang="en-US">100,3,16,32</span></font>），<font face="Liberation Serif, serif"><span lang="en-US">Caffe</span></font>采取的也是这种方式。第<font face="Liberation Serif, serif"><span lang="en-US">0</span></font>个维度是样本维，代表样本的数目，第<font face="Liberation Serif, serif"><span lang="en-US">1</span></font>个维度是通道维，代表颜色通道数。后面两个就是高和宽了。这种<font face="Liberation Serif, serif"><span lang="en-US">theano</span></font>风格的数据组织方法，称为“<font face="Liberation Serif, serif"><span lang="en-US">channels_first”</span></font>，即通道维靠前。</span></p>
<p><span style="background: #ffff00">而<font face="Liberation Serif, serif"><span lang="en-US">TensorFlow</span></font>，的表达形式是（<font face="Liberation Serif, serif"><span lang="en-US">100,16,32,3</span></font>），即把通道维放在了最后，这种数据组织方式称为“<font face="Liberation Serif, serif"><span lang="en-US">channels_last”</span></font>。</span></p>
<p><font face="Liberation Serif, serif"><span lang="en-US"><span style="background: #ffff00">Keras</span></font>默认的数据组织形式在<font face="Liberation Serif, serif"><span lang="en-US">~/.keras/keras.json</span></font>中规定，可查看该文件的</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">image_data_format</span></code></span></font><span style="background: #ffff00">一项查看，也可在代码中通过<font face="Liberation Serif, serif"><span lang="en-US">K.image_data_format()</span></font>函数返回，请在网络的训练和测试中保持维度顺序一致。</span></p>
<p><span style="background: #ffff00">唉，真是蛋疼，你们商量好不行吗？</span></p>
<h2><a name="functional"></a><a name="_4"></a><span style="background: #ffff00">函数式模型</span></h2>
</body>
</html>