<!DOCTYPE html>
    <html><head><meta charset="UTF-8">
    </head><body>
    <p><a href="http://keras-cn.readthedocs.io/en/latest/">原文链接</a></p>
        <div class="section">
<h1 id="_1">图片预处理</h1>
<h2 id="imagedatagenerator">图片生成器ImageDataGenerator</h2>
<pre><code class="python">keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,
    samplewise_center=False,
    featurewise_std_normalization=False,
    samplewise_std_normalization=False,
    zca_whitening=False,
    zca_epsilon=1e-6,
    rotation_range=0.,
    width_shift_range=0.,
    height_shift_range=0.,
    shear_range=0.,
    zoom_range=0.,
    channel_shift_range=0.,
    fill_mode='nearest',
    cval=0.,
    horizontal_flip=False,
    vertical_flip=False,
    rescale=None,
    preprocessing_function=None,
    data_format=K.image_data_format())
</code></pre>
<p>用以生成一个batch的图像数据，支持实时数据提升。训练时该函数会无限生成数据，直到达到规定的epoch次数为止。</p>
<h3 id="_2">参数</h3>
<ul>
<li>
<p>featurewise_center：布尔值，使输入数据集去中心化（均值为0）, 按feature执行</p>
</li>
<li>
<p>samplewise_center：布尔值，使输入数据的每个样本均值为0</p>
</li>
<li>
<p>featurewise_std_normalization：布尔值，将输入除以数据集的标准差以完成标准化, 按feature执行</p>
</li>
<li>
<p>samplewise_std_normalization：布尔值，将输入的每个样本除以其自身的标准差</p>
</li>
<li>
<p>zca_whitening：布尔值，对输入数据施加ZCA白化</p>
</li>
<li>
<p>zca_epsilon: ZCA使用的eposilon，默认1e-6</p>
</li>
<li>
<p>rotation_range：整数，数据提升时图片随机转动的角度</p>
</li>
<li>
<p>width_shift_range：浮点数，图片宽度的某个比例，数据提升时图片水平偏移的幅度</p>
</li>
<li>
<p>height_shift_range：浮点数，图片高度的某个比例，数据提升时图片竖直偏移的幅度</p>
</li>
<li>
<p>shear_range：浮点数，剪切强度（逆时针方向的剪切变换角度）</p>
</li>
<li>
<p>zoom_range：浮点数或形如<code>[lower,upper]</code>的列表，随机缩放的幅度，若为浮点数，则相当于<code>[lower,upper] = [1 - zoom_range, 1+zoom_range]</code></p>
</li>
<li>
<p>channel_shift_range：浮点数，随机通道偏移的幅度</p>
</li>
<li>
<p>fill_mode：；‘constant’，‘nearest’，‘reflect’或‘wrap’之一，当进行变换时超出边界的点将根据本参数给定的方法进行处理</p>
</li>
<li>
<p>cval：浮点数或整数，当<code>fill_mode=constant</code>时，指定要向超出边界的点填充的值</p>
</li>
<li>
<p>horizontal_flip：布尔值，进行随机水平翻转</p>
</li>
<li>
<p>vertical_flip：布尔值，进行随机竖直翻转</p>
</li>
<li>
<p>rescale: 重放缩因子,默认为None. 如果为None或0则不进行放缩,否则会将该数值乘到数据上(在应用其他变换之前)</p>
</li>
<li>
<p>preprocessing_function: 将被应用于每个输入的函数。该函数将在任何其他修改之前运行。该函数接受一个参数，为一张图片（秩为3的numpy array），并且输出一个具有相同shape的numpy array</p>
</li>
<li>
<p>data_format：字符串，“channel_first”或“channel_last”之一，代表图像的通道维的位置。该参数是Keras 1.x中的image_dim_ordering，“channel_last”对应原本的“tf”，“channel_first”对应原本的“th”。以128x128的RGB图像为例，“channel_first”应将数据组织为（3,128,128），而“channel_last”应将数据组织为（128,128,3）。该参数的默认值是<code>~/.keras/keras.json</code>中设置的值，若从未设置过，则为“channel_last”</p>
</li>
</ul>
<hr/>
<h3 id="_3">方法</h3>
<ul>
<li>
<p>fit(x, augment=False, rounds=1)：计算依赖于数据的变换所需要的统计信息(均值方差等),只有使用<code>featurewise_center</code>，<code>featurewise_std_normalization</code>或<code>zca_whitening</code>时需要此函数。</p>
<ul>
<li>
<p>X：numpy array，样本数据，秩应为4.在黑白图像的情况下channel轴的值为1，在彩色图像情况下值为3</p>
</li>
<li>
<p>augment：布尔值，确定是否使用随即提升过的数据</p>
</li>
<li>
<p>round：若设<code>augment=True</code>，确定要在数据上进行多少轮数据提升，默认值为1</p>
</li>
<li>
<p>seed: 整数,随机数种子</p>
</li>
</ul>
</li>
<li>
<p>flow(self, X, y, batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='png')：接收numpy数组和标签为参数,生成经过数据提升或标准化后的batch数据,并在一个无限循环中不断的返回batch数据</p>
<ul>
<li>
<p>x：样本数据，秩应为4.在黑白图像的情况下channel轴的值为1，在彩色图像情况下值为3</p>
</li>
<li>
<p>y：标签</p>
</li>
<li>
<p>batch_size：整数，默认32</p>
</li>
<li>
<p>shuffle：布尔值，是否随机打乱数据，默认为True</p>
</li>
<li>
<p>save_to_dir：None或字符串，该参数能让你将提升后的图片保存起来，用以可视化</p>
</li>
<li>
<p>save_prefix：字符串，保存提升后图片时使用的前缀, 仅当设置了<code>save_to_dir</code>时生效</p>
</li>
<li>
<p>save_format："png"或"jpeg"之一，指定保存图片的数据格式,默认"jpeg"</p>
</li>
<li>
<p>yields:形如(x,y)的tuple,x是代表图像数据的numpy数组.y是代表标签的numpy数组.该迭代器无限循环.</p>
</li>
<li>
<p>seed: 整数,随机数种子</p>
</li>
</ul>
</li>
<li>
<p>flow_from_directory(directory): 以文件夹路径为参数,生成经过数据提升/归一化后的数据,在一个无限循环中无限产生batch数据</p>
<ul>
<li>directory: 目标文件夹路径,对于每一个类,该文件夹都要包含一个子文件夹.子文件夹中任何JPG、PNG和BNP的图片都会被生成器使用.详情请查看<a href="https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d"><font color="#FF0000">此脚本</font></a></li>
<li>target_size: 整数tuple,默认为(256, 256). 图像将被resize成该尺寸</li>
<li>color_mode: 颜色模式,为"grayscale","rgb"之一,默认为"rgb".代表这些图片是否会被转换为单通道或三通道的图片.</li>
<li>classes: 可选参数,为子文件夹的列表,如['dogs','cats']默认为None. 若未提供,则该类别列表将从<code>directory</code>下的子文件夹名称/结构自动推断。每一个子文件夹都会被认为是一个新的类。(类别的顺序将按照字母表顺序映射到标签值)。通过属性<code>class_indices</code>可获得文件夹名与类的序号的对应字典。</li>
<li>class_mode: "categorical", "binary", "sparse"或None之一. 默认为"categorical. 该参数决定了返回的标签数组的形式, "categorical"会返回2D的one-hot编码标签,"binary"返回1D的二值标签."sparse"返回1D的整数标签,如果为None则不返回任何标签, 生成器将仅仅生成batch数据, 这种情况在使用<code>model.predict_generator()</code>和<code>model.evaluate_generator()</code>等函数时会用到.</li>
<li>batch_size: batch数据的大小,默认32</li>
<li>shuffle: 是否打乱数据,默认为True</li>
<li>seed: 可选参数,打乱数据和进行变换时的随机数种子</li>
<li>save_to_dir: None或字符串，该参数能让你将提升后的图片保存起来，用以可视化</li>
<li>save_prefix：字符串，保存提升后图片时使用的前缀, 仅当设置了<code>save_to_dir</code>时生效</li>
<li>save_format："png"或"jpeg"之一，指定保存图片的数据格式,默认"jpeg"</li>
<li>flollow_links: 是否访问子文件夹中的软链接</li>
</ul>
</li>
</ul>
<h3 id="_4">例子</h3>
<p>使用<code>.flow()</code>的例子</p>
<pre><code class="python">(x_train, y_train), (x_test, y_test) = cifar10.load_data()
y_train = np_utils.to_categorical(y_train, num_classes)
y_test = np_utils.to_categorical(y_test, num_classes)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True)

# compute quantities required for featurewise normalization
# (std, mean, and principal components if ZCA whitening is applied)
datagen.fit(x_train)

# fits the model on batches with real-time data augmentation:
model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),
                    steps_per_epoch=len(x_train), epochs=epochs)

# here's a more "manual" example
for e in range(epochs):
    print 'Epoch', e
    batches = 0
    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):
        loss = model.train(x_batch, y_batch)
        batches += 1
        if batches &gt;= len(x_train) / 32:
            # we need to break the loop by hand because
            # the generator loops indefinitely
            break
</code></pre>
<p>使用<code>.flow_from_directory(directory)</code>的例子</p>
<pre><code class="python">train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        'data/train',
        target_size=(150, 150),
        batch_size=32,
        class_mode='binary')

validation_generator = test_datagen.flow_from_directory(
        'data/validation',
        target_size=(150, 150),
        batch_size=32,
        class_mode='binary')

model.fit_generator(
        train_generator,
        steps_per_epoch=2000,
        epochs=50,
        validation_data=validation_generator,
        validation_steps=800)
</code></pre>
<p>同时变换图像和mask</p>
<pre><code class="python"># we create two instances with the same arguments
data_gen_args = dict(featurewise_center=True,
                     featurewise_std_normalization=True,
                     rotation_range=90.,
                     width_shift_range=0.1,
                     height_shift_range=0.1,
                     zoom_range=0.2)
image_datagen = ImageDataGenerator(**data_gen_args)
mask_datagen = ImageDataGenerator(**data_gen_args)

# Provide the same seed and keyword arguments to the fit and flow methods
seed = 1
image_datagen.fit(images, augment=True, seed=seed)
mask_datagen.fit(masks, augment=True, seed=seed)

image_generator = image_datagen.flow_from_directory(
    'data/images',
    class_mode=None,
    seed=seed)

mask_generator = mask_datagen.flow_from_directory(
    'data/masks',
    class_mode=None,
    seed=seed)

# combine generators into one which yields image and masks
train_generator = zip(image_generator, mask_generator)

model.fit_generator(
    train_generator,
    steps_per_epoch=2000,
    epochs=50)
</code></pre>
</div>
    </body></html>