<!DOCTYPE html>
    <html><head><meta charset="UTF-8">
    </head><body>
    <p><a href="http://keras-cn.readthedocs.io/en/latest/">原文链接</a></p>
        <div class="section">
<h1 id="locallyconnceted">局部连接层LocallyConnceted</h1>
<h2 id="locallyconnected1d">LocallyConnected1D层</h2>
<pre><code class="python">keras.layers.local.LocallyConnected1D(filters, kernel_size, strides=1, padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)
</code></pre>
<p><code>LocallyConnected1D</code>层与<code>Conv1D</code>工作方式类似，唯一的区别是不进行权值共享。即施加在不同输入位置的滤波器是不一样的。</p>
<h3 id="_1">参数</h3>
<ul>
<li>
<p>filters：卷积核的数目（即输出的维度）</p>
</li>
<li>
<p>kernel_size：整数或由单个整数构成的list/tuple，卷积核的空域或时域窗长度</p>
</li>
<li>
<p>strides：整数或由单个整数构成的list/tuple，为卷积的步长。任何不为1的strides均与任何不为1的dilation_rata均不兼容</p>
</li>
<li>
<p>padding：补0策略，目前仅支持<code>valid</code>（大小写敏感），<code>same</code>可能会在将来支持。</p>
</li>
<li>
<p>activation：激活函数，为预定义的激活函数名（参考<a href="../../other/activations">激活函数</a>），或逐元素（element-wise）的Theano函数。如果不指定该参数，将不会使用任何激活函数（即使用线性激活函数：a(x)=x）</p>
</li>
<li>
<p>dilation_rate：整数或由单个整数构成的list/tuple，指定dilated convolution中的膨胀比例。任何不为1的dilation_rata均与任何不为1的strides均不兼容。</p>
</li>
<li>
<p>use_bias:布尔值，是否使用偏置项</p>
</li>
<li>
<p>kernel_initializer：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考<a href="../../other/initializations">initializers</a></p>
</li>
<li>
<p>bias_initializer：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考<a href="../../other/initializations">initializers</a></p>
</li>
<li>
<p>kernel_regularizer：施加在权重上的正则项，为<a href="../../other/regularizers">Regularizer</a>对象</p>
</li>
<li>
<p>bias_regularizer：施加在偏置向量上的正则项，为<a href="../../other/regularizers">Regularizer</a>对象</p>
</li>
<li>
<p>activity_regularizer：施加在输出上的正则项，为<a href="../../other/regularizers">Regularizer</a>对象</p>
</li>
<li>
<p>kernel_constraints：施加在权重上的约束项，为<a href="../../other/constraints">Constraints</a>对象</p>
</li>
<li>
<p>bias_constraints：施加在偏置上的约束项，为<a href="../../other/constraints">Constraints</a>对象</p>
</li>
</ul>
<h3 id="shape">输入shape</h3>
<p>形如（samples，steps，input_dim）的3D张量</p>
<h3 id="shape_1">输出shape</h3>
<p>形如（samples，new_steps，nb_filter）的3D张量，因为有向量填充的原因，<code>steps</code>的值会改变</p>
<hr/>
<h2 id="locallyconnected2d">LocallyConnected2D层</h2>
<pre><code class="python">keras.layers.local.LocallyConnected2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)
</code></pre>
<p><code>LocallyConnected2D</code>层与<code>Convolution2D</code>工作方式类似，唯一的区别是不进行权值共享。即施加在不同输入patch的滤波器是不一样的，当使用该层作为模型首层时，需要提供参数<code>input_dim</code>或<code>input_shape</code>参数。参数含义参考<code>Convolution2D</code>。</p>
<h3 id="_2">参数</h3>
<ul>
<li>
<p>filters：卷积核的数目（即输出的维度）</p>
</li>
<li>
<p>kernel_size：单个整数或由两个整数构成的list/tuple，卷积核的宽度和长度。如为单个整数，则表示在各个空间维度的相同长度。</p>
</li>
<li>
<p>strides：单个整数或由两个整数构成的list/tuple，为卷积的步长。如为单个整数，则表示在各个空间维度的相同步长。</p>
</li>
<li>
<p>padding：补0策略，目前仅支持<code>valid</code>（大小写敏感），<code>same</code>可能会在将来支持。</p>
</li>
<li>
<p>activation：激活函数，为预定义的激活函数名（参考<a href="../../other/activations">激活函数</a>），或逐元素（element-wise）的Theano函数。如果不指定该参数，将不会使用任何激活函数（即使用线性激活函数：a(x)=x）</p>
</li>
<li>
<p>data_format：字符串，“channels_first”或“channels_last”之一，代表图像的通道维的位置。该参数是Keras 1.x中的image_dim_ordering，“channels_last”对应原本的“tf”，“channels_first”对应原本的“th”。以128x128的RGB图像为例，“channels_first”应将数据组织为（3,128,128），而“channels_last”应将数据组织为（128,128,3）。该参数的默认值是<code>~/.keras/keras.json</code>中设置的值，若从未设置过，则为“channels_last”。</p>
</li>
<li>
<p>use_bias:布尔值，是否使用偏置项</p>
</li>
<li>
<p>kernel_initializer：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考<a href="../../other/initializations">initializers</a></p>
</li>
<li>
<p>bias_initializer：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考<a href="../../other/initializations">initializers</a></p>
</li>
<li>
<p>kernel_regularizer：施加在权重上的正则项，为<a href="../../other/regularizers">Regularizer</a>对象</p>
</li>
<li>
<p>bias_regularizer：施加在偏置向量上的正则项，为<a href="../../other/regularizers">Regularizer</a>对象</p>
</li>
<li>
<p>activity_regularizer：施加在输出上的正则项，为<a href="../../other/regularizers">Regularizer</a>对象</p>
</li>
<li>
<p>kernel_constraints：施加在权重上的约束项，为<a href="../../other/constraints">Constraints</a>对象</p>
</li>
<li>
<p>bias_constraints：施加在偏置上的约束项，为<a href="../../other/constraints">Constraints</a>对象</p>
</li>
</ul>
<h3 id="shape_2">输入shape</h3>
<p>‘channels_first’模式下，输入形如（samples,channels，rows，cols）的4D张量</p>
<p>‘channels_last’模式下，输入形如（samples，rows，cols，channels）的4D张量</p>
<p>注意这里的输入shape指的是函数内部实现的输入shape，而非函数接口应指定的<code>input_shape</code>，请参考下面提供的例子。</p>
<h3 id="shape_3">输出shape</h3>
<p>‘channels_first’模式下，为形如（samples，nb_filter, new_rows, new_cols）的4D张量</p>
<p>‘channels_last’模式下，为形如（samples，new_rows, new_cols，nb_filter）的4D张量</p>
<p>输出的行列数可能会因为填充方法而改变</p>
<h3 id="_3">例子</h3>
<pre><code class="python"># apply a 3x3 unshared weights convolution with 64 output filters on a 32x32 image
# with `data_format="channels_last"`:
model = Sequential()
model.add(LocallyConnected2D(64, (3, 3), input_shape=(32, 32, 3)))
# now model.output_shape == (None, 30, 30, 64)
# notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64 parameters

# add a 3x3 unshared weights convolution on top, with 32 output filters:
model.add(LocallyConnected2D(32, (3, 3)))
# now model.output_shape == (None, 28, 28, 32)
</code></pre>
</div>
    </body></html>