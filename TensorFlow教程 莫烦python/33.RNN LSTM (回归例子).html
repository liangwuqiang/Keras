<!DOCTYPE html>
    <html><head><meta charset="UTF-8">
    </head><body>
    <p><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/">原文链接</a></p>
        <div class="tut-main-content-pad">
<br>
<h1>RNN LSTM (回归例子)</h1>
<p style="text-align: center;">
        
          作者: <strong>莫烦</strong>   
        
        编辑: <strong>莫烦</strong>   
        
      </p>
<p>学习资料:</p>
<ul>
<li><a href="https://github.com/MorvanZhou/tutorials/tree/master/tensorflowTUT/tf20_RNN2.2">相关代码</a></li>
<li>为 TF 2017 打造的<a href="https://github.com/MorvanZhou/Tensorflow-Tutorial">新版可视化教学代码</a></li>
<li>机器学习-简介系列 <a href="/tutorials/machine-learning/ML-intro/2-3-RNN/">什么是RNN</a></li>
<li>机器学习-简介系列 <a href="/tutorials/machine-learning/ML-intro/2-4-LSTM/">什么是LSTM RNN</a></li>
<li>Tensorflow 的 <a href="http://r2rt.com/styles-of-truncated-backpropagation.html">bptt 形式理解</a></li>
</ul>
<h4 class="tut-h4-pad" id="设置 RNN 的参数">设置 RNN 的参数</h4>
<p>这次我们会使用 RNN 来进行回归的训练 (Regression). 会继续使用到自己创建的 sin 曲线预测一条 cos 曲线.
接下来我们先确定 RNN 的各种参数(super-parameters):</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="n">BATCH_START</span> <span class="o">=</span> <span class="mi">0</span>     <span class="c"># 建立 batch data 时候的 index</span>
<span class="n">TIME_STEPS</span> <span class="o">=</span> <span class="mi">20</span>     <span class="c"># backpropagation through time 的 time_steps</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">50</span>     
<span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="mi">1</span>      <span class="c"># sin 数据输入 size</span>
<span class="n">OUTPUT_SIZE</span> <span class="o">=</span> <span class="mi">1</span>     <span class="c"># cos 数据输出 size</span>
<span class="n">CELL_SIZE</span> <span class="o">=</span> <span class="mi">10</span>      <span class="c"># RNN 的 hidden unit size </span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">0.006</span>          <span class="c"># learning rate</span>
</code></pre>
</div>
<h4 class="tut-h4-pad" id="数据生成">数据生成</h4>
<p>定义一个生成数据的 <code class="highlighter-rouge">get_batch</code> function:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_batch</span><span class="p">():</span>
    <span class="k">global</span> <span class="n">BATCH_START</span><span class="p">,</span> <span class="n">TIME_STEPS</span>
    <span class="c"># xs shape (50batch, 20steps)</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">BATCH_START</span><span class="p">,</span> <span class="n">BATCH_START</span><span class="o">+</span><span class="n">TIME_STEPS</span><span class="o">*</span><span class="n">BATCH_SIZE</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">TIME_STEPS</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
    <span class="n">seq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">BATCH_START</span> <span class="o">+=</span> <span class="n">TIME_STEPS</span>
    <span class="c"># returned seq, res and xs: shape (batch, step, input)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">seq</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">res</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">xs</span><span class="p">]</span>
</code></pre>
</div>
<p><img alt="RNN LSTM (回归例子)806" class="course-image" src="images/dd07d6a4863bff9cac301fb5170a78ce.png"/></p>
<div>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle" data-ad-client="ca-pub-4601203457616636" data-ad-format="fluid" data-ad-layout="in-article" data-ad-slot="3397817325" style="display:block; text-align:center;"></ins>
<script>
       (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>
<h4 class="tut-h4-pad" id="定义 LSTMRNN 的主体结构">定义 LSTMRNN 的主体结构</h4>
<p>使用一个 class 来定义这次的 LSTMRNN 会更加方便. 第一步定义 class 中的 <code class="highlighter-rouge">__init__</code> 传入各种参数:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LSTMRNN</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">cell_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">=</span> <span class="n">n_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cell_size</span> <span class="o">=</span> <span class="n">cell_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s">'inputs'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">input_size</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">'xs'</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ys</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">output_size</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">'ys'</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'in_hidden'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_input_layer</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'LSTM_cell'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_cell</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'out_hidden'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_output_layer</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s">'cost'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">compute_cost</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s">'train'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">LR</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cost</span><span class="p">)</span>
</code></pre>
</div>
<p>设置 <code class="highlighter-rouge">add_input_layer</code> 功能, 添加 <code class="highlighter-rouge">input_layer</code>:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">add_input_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,):</span>
        <span class="n">l_in_x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">'2_2D'</span><span class="p">)</span>  <span class="c"># (batch*n_step, in_size)</span>
        <span class="c"># Ws (in_size, cell_size)</span>
        <span class="n">Ws_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_variable</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">input_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell_size</span><span class="p">])</span>
        <span class="c"># bs (cell_size, )</span>
        <span class="n">bs_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bias_variable</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">cell_size</span><span class="p">,])</span>
        <span class="c"># l_in_y = (batch * n_steps, cell_size)</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s">'Wx_plus_b'</span><span class="p">):</span>
            <span class="n">l_in_y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">l_in_x</span><span class="p">,</span> <span class="n">Ws_in</span><span class="p">)</span> <span class="o">+</span> <span class="n">bs_in</span>
        <span class="c"># reshape l_in_y ==&gt; (batch, n_steps, cell_size)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l_in_y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">l_in_y</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell_size</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">'2_3D'</span><span class="p">)</span>
</code></pre>
</div>
<p>设置 <code class="highlighter-rouge">add_cell</code> 功能, 添加 <code class="highlighter-rouge">cell</code>, 注意这里的 <code class="highlighter-rouge">self.cell_init_state</code>, 因为我们在 training 的时候, 这个地方要特别说明.</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">add_cell</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">lstm_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cell_size</span><span class="p">,</span> <span class="n">forget_bias</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">state_is_tuple</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s">'initial_state'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cell_init_state</span> <span class="o">=</span> <span class="n">lstm_cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cell_outputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell_final_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span>
            <span class="n">lstm_cell</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">l_in_y</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cell_init_state</span><span class="p">,</span> <span class="n">time_major</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre>
</div>
<p>设置 <code class="highlighter-rouge">add_output_layer</code> 功能, 添加 <code class="highlighter-rouge">output_layer</code>:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">add_output_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c"># shape = (batch * steps, cell_size)</span>
        <span class="n">l_out_x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cell_outputs</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell_size</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">'2_2D'</span><span class="p">)</span>
        <span class="n">Ws_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weight_variable</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">cell_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">])</span>
        <span class="n">bs_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bias_variable</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span> <span class="p">])</span>
        <span class="c"># shape = (batch * steps, output_size)</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s">'Wx_plus_b'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">l_out_x</span><span class="p">,</span> <span class="n">Ws_out</span><span class="p">)</span> <span class="o">+</span> <span class="n">bs_out</span>
</code></pre>
</div>
<p>添加 RNN 中剩下的部分:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">compute_cost</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">legacy_seq2seq</span><span class="o">.</span><span class="n">sequence_loss_by_example</span><span class="p">(</span>
            <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">'reshape_pred'</span><span class="p">)],</span>
            <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ys</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">'reshape_target'</span><span class="p">)],</span>
            <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)],</span>
            <span class="n">average_across_timesteps</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">softmax_loss_function</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ms_error</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s">'losses'</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s">'average_cost'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">div</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'losses_sum'</span><span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="s">'average_cost'</span><span class="p">)</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s">'cost'</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">ms_error</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_target</span><span class="p">,</span> <span class="n">y_pre</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">y_target</span><span class="p">,</span> <span class="n">y_pre</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_weight_variable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'weights'</span><span class="p">):</span>
        <span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_normal_initializer</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">1.</span><span class="p">,)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_bias_variable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'biases'</span><span class="p">):</span>
        <span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">)</span>
</code></pre>
</div>
<h4 class="tut-h4-pad" id="训练 LSTMRNN">训练 LSTMRNN</h4>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="c"># 搭建 LSTMRNN 模型</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LSTMRNN</span><span class="p">(</span><span class="n">TIME_STEPS</span><span class="p">,</span> <span class="n">INPUT_SIZE</span><span class="p">,</span> <span class="n">OUTPUT_SIZE</span><span class="p">,</span> <span class="n">CELL_SIZE</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>
    <span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
    <span class="c"># sess.run(tf.initialize_all_variables()) # tf 马上就要废弃这种写法</span>
    <span class="c"># 替换成下面的写法:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    
    <span class="c"># 训练 200 次</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
        <span class="n">seq</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">xs</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">()</span>  <span class="c"># 提取 batch data</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c"># 初始化 data</span>
            <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">xs</span><span class="p">:</span> <span class="n">seq</span><span class="p">,</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">ys</span><span class="p">:</span> <span class="n">res</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">model</span><span class="o">.</span><span class="n">xs</span><span class="p">:</span> <span class="n">seq</span><span class="p">,</span>
                <span class="n">model</span><span class="o">.</span><span class="n">ys</span><span class="p">:</span> <span class="n">res</span><span class="p">,</span>
                <span class="n">model</span><span class="o">.</span><span class="n">cell_init_state</span><span class="p">:</span> <span class="n">state</span>    <span class="c"># 保持 state 的连续性</span>
            <span class="p">}</span>
        
        <span class="c"># 训练</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
            <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">train_op</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">cost</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">cell_final_state</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">pred</span><span class="p">],</span>
            <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
        
        <span class="c"># 打印 cost 结果</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'cost: '</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</code></pre>
</div>
<p>最后<code class="highlighter-rouge">cost</code>结果如下:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>cost:  48.4813
cost:  9.9825
cost:  7.9988
cost:  5.8154
cost:  3.9268
cost:  2.4393
cost:  2.9643
cost:  0.4856
cost:  0.5175
cost:  0.7858
</code></pre>
</div>
<p style="font-size: 0.8em; padding:4em 1em 0.5em 1em; margin: 0 auto;">
        如果你觉得这篇文章或视频对你的学习很有帮助, 请你也分享它, 让它能再次帮助到更多的需要学习的人.

        莫烦没有正式的经济来源, 如果你也想支持 <strong>莫烦Python</strong> 并看到更好的教学内容, 赞助他一点点, 作为鼓励他继续开源的动力.
      </p>
<!-- donation -->
<div id="bottom-donation-section">
<h3 id="bottom-donation-title">支持 让教学变得更优秀</h3>
<br>
<div>
<a href="/support/" id="bottom-donation-button"><strong>点我 赞助 莫烦</strong></a>
</div>
<br>
</br></br></div>
<hr>
</hr></br></div>
    </body></html>