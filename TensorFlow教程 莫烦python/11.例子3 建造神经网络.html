<<<<<<< HEAD
<!DOCTYPE html>
    <html><head><meta charset="UTF-8">
    </head><body>
    <p><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/">原文链接</a></p>
        <div class="tut-main-content-pad">
<hr>
<h1>例子3 建造神经网络</h1>
<p style="text-align: center;">
        
          作者: <strong>赵孔亚</strong>   
        
        编辑: <strong>莫烦</strong>   
        
          2016-11-03
        
      </p>
<p>学习资料:</p>
<ul>
<li><a href="https://github.com/MorvanZhou/tutorials/blob/master/tensorflowTUT/tensorflow11_build_network.py">相关代码</a></li>
<li>为 TF 2017 打造的<a href="https://github.com/MorvanZhou/Tensorflow-Tutorial">新版可视化教学代码</a></li>
</ul>
<p>这次提到了怎样建造一个完整的神经网络,包括添加神经层,计算误差,训练步骤,判断是否在学习.</p>
<p>本次课程，我们会在上节课的基础上，继续讲解如何构建神经层。</p>
<h4 class="tut-h4-pad" id="add_layer 功能">add_layer 功能</h4>
<p>首先，我们导入本次所需的模块。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</code></pre>
</div>
<p>构造添加一个神经层的函数。（在上次课程中有详细介绍）</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">add_layer</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">activation_function</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">Weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">]))</span>
    <span class="n">biases</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_size</span><span class="p">])</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">Wx_plus_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">Weights</span><span class="p">)</span> <span class="o">+</span> <span class="n">biases</span>
    <span class="k">if</span> <span class="n">activation_function</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">Wx_plus_b</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">activation_function</span><span class="p">(</span><span class="n">Wx_plus_b</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span>
</code></pre>
</div>
<h4 class="tut-h4-pad" id="导入数据">导入数据</h4>
<p>构建所需的数据。
这里的<code class="highlighter-rouge">x_data</code>和<code class="highlighter-rouge">y_data</code>并不是严格的一元二次函数的关系，因为我们多加了一个<code class="highlighter-rouge">noise</code>,这样看起来会更像真实情况。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">300</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">x_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="n">noise</span>
</code></pre>
</div>
<p>利用占位符定义我们所需的神经网络的输入。
<code class="highlighter-rouge">tf.placeholder()</code>就是代表占位符，这里的<code class="highlighter-rouge">None</code>代表无论输入有多少都可以，因为输入只有一个特征，所以这里是<code class="highlighter-rouge">1</code>。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">xs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</code></pre>
</div>
<p>接下来，我们就可以开始定义神经层了。
通常神经层都包括输入层、隐藏层和输出层。这里的输入层只有一个属性，
所以我们就只有一个输入；隐藏层我们可以自己假设，这里我们假设隐藏层有10个神经元；
输出层和输入层的结构是一样的，所以我们的输出层也是只有一层。
所以，我们构建的是——输入层1个、隐藏层10个、输出层1个的神经网络。</p>
<h4 class="tut-h4-pad" id="搭建网络">搭建网络</h4>
<p>下面，我们开始定义隐藏层,利用之前的<code class="highlighter-rouge">add_layer()</code>函数，这里使用 Tensorflow 自带的激励函数<code class="highlighter-rouge">tf.nn.relu</code>。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">l1</span> <span class="o">=</span> <span class="n">add_layer</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">activation_function</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
</code></pre>
</div>
<p>接着，定义输出层。此时的输入就是隐藏层的输出——<code class="highlighter-rouge">l1</code>，输入有10层（隐藏层的输出层），输出有1层。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">prediction</span> <span class="o">=</span> <span class="n">add_layer</span><span class="p">(</span><span class="n">l1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">activation_function</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</code></pre>
</div>
<p>计算预测值<code class="highlighter-rouge">prediction</code>和真实值的误差，对二者差的平方求和再取平均。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">ys</span> <span class="o">-</span> <span class="n">prediction</span><span class="p">),</span>
                     <span class="n">reduction_indices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</code></pre>
</div>
<p>接下来，是很关键的一步，如何让机器学习提升它的准确率。<code class="highlighter-rouge">tf.train.GradientDescentOptimizer()</code>中的值通常都小于1，这里取的是<code class="highlighter-rouge">0.1</code>，代表以<code class="highlighter-rouge">0.1</code>的效率来最小化误差<code class="highlighter-rouge">loss</code>。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">train_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</code></pre>
</div>
<p>使用变量时，都要对它进行初始化，这是必不可少的。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># init = tf.initialize_all_variables() # tf 马上就要废弃这种写法</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>  <span class="c"># 替换成这样就好</span>
</code></pre>
</div>
<p>定义<code class="highlighter-rouge">Session</code>，并用 <code class="highlighter-rouge">Session</code> 来执行 <code class="highlighter-rouge">init</code> 初始化步骤。
（注意：在<code class="highlighter-rouge">tensorflow</code>中，只有<code class="highlighter-rouge">session.run()</code>才会执行我们定义的运算。）</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
</code></pre>
</div>
<h4 class="tut-h4-pad" id="训练">训练</h4>
<p>下面，让机器开始学习。</p>
<p>比如这里，我们让机器学习1000次。机器学习的内容是<code class="highlighter-rouge">train_step</code>, 用 <code class="highlighter-rouge">Session</code> 来 <code class="highlighter-rouge">run</code> 每一次 training 的数据，逐步提升神经网络的预测准确性。
(注意：当运算要用到<code class="highlighter-rouge">placeholder</code>时，就需要<code class="highlighter-rouge">feed_dict</code>这个字典来指定输入。)</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="c"># training</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_step</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">xs</span><span class="p">:</span> <span class="n">x_data</span><span class="p">,</span> <span class="n">ys</span><span class="p">:</span> <span class="n">y_data</span><span class="p">})</span>
</code></pre>
</div>
<p>每50步我们输出一下机器学习的误差。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code>    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c"># to see the step improvement</span>
        <span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">xs</span><span class="p">:</span> <span class="n">x_data</span><span class="p">,</span> <span class="n">ys</span><span class="p">:</span> <span class="n">y_data</span><span class="p">}))</span>
</code></pre>
</div>
<p>在电脑上运行本次代码的结果为：</p>
<p><img class="course-image" src="images/640ea5de8980dcb59937ab83b4c752aa.png"/></p>
<p>通过上图可以看出，误差在逐渐减小，这说明机器学习是有积极的效果的。</p>
<p style="font-size: 0.8em; padding:4em 1em 0.5em 1em; margin: 0 auto;">
        如果你觉得这篇文章或视频对你的学习很有帮助, 请你也分享它, 让它能再次帮助到更多的需要学习的人.

        莫烦没有正式的经济来源, 如果你也想支持 <strong>莫烦Python</strong> 并看到更好的教学内容, 赞助他一点点, 作为鼓励他继续开源的动力.
      </p>
<!-- donation -->
<div id="bottom-donation-section">
<h3 id="bottom-donation-title">支持 让教学变得更优秀</h3>
<br>
<div>
<a href="/support/" id="bottom-donation-button"><strong>点我 赞助 莫烦</strong></a>
</div>
<br>
</br></br></div>
<hr>
</hr></hr></div>
    </body></html>
=======
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8"/>
	<title></title>
	<meta name="generator" content="LibreOffice 5.1.4.2 (Linux)"/>
	<meta name="created" content="00:00:00"/>
	<meta name="changed" content="2017-09-19T16:15:57.590162790"/>
	<meta name="" content=""/>
	<style type="text/css">
		pre.ctl { font-family: "Liberation Mono", monospace }
		code.ctl { font-family: "Liberation Mono", monospace }
	</style>
</head>
<body lang="zh-CN" dir="ltr">
<p><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/"><span style="background: #ffff00">原文链接</span></a></p>
<hr/>

<h1><span style="background: #ffff00">例子<font face="Thorndale, serif"><font size="6" style="font-size: 24pt"><span lang="en-US">3
</span></font></font>建造神经网络</span></h1>
<p align="center"><span style="background: #ffff00">作者<font face="Liberation Serif, serif"><span lang="en-US">:
</span></span></font><strong><span style="background: #ffff00">赵孔亚</span></strong><span style="background: #ffff00">
&nbsp;&nbsp; 编辑<font face="Liberation Serif, serif"><span lang="en-US">:
</span></span></font><strong><span style="background: #ffff00">莫烦</span></strong><span style="background: #ffff00">
&nbsp;&nbsp; <font face="Liberation Serif, serif"><span lang="en-US">2016-11-03
</span></span></font>
</p>
<p><span style="background: #ffff00">学习资料<font face="Liberation Serif, serif"><span lang="en-US">:</span></span></font></p>
<ul>
	<li/>
<p style="margin-bottom: 0cm"><span style="background: #ffff00"><a href="https://github.com/MorvanZhou/tutorials/blob/master/tensorflowTUT/tensorflow11_build_network.py">相关代码</a>
	</span>
	</p>
	<li/>
<p><span style="background: #ffff00">为 <font face="Liberation Serif, serif"><span lang="en-US">TF
	2017 </span></font>打造的<a href="https://github.com/MorvanZhou/Tensorflow-Tutorial">新版可视化教学代码</a>
	</span>
	</p>
</ul>
<p><span style="background: #ffff00">这次提到了怎样建造一个完整的神经网络<font face="Liberation Serif, serif"><span lang="en-US">,</span></font>包括添加神经层<font face="Liberation Serif, serif"><span lang="en-US">,</span></font>计算误差<font face="Liberation Serif, serif"><span lang="en-US">,</span></font>训练步骤<font face="Liberation Serif, serif"><span lang="en-US">,</span></font>判断是否在学习<font face="Liberation Serif, serif"><span lang="en-US">.</span></span></font></p>
<p><span style="background: #ffff00">本次课程，我们会在上节课的基础上，继续讲解如何构建神经层。</span></p>
<h4><a name="add_layer 功能"></a><font face="Liberation Serif, serif"><span lang="en-US"><span style="background: #ffff00">add_layer
</span></font>功能</span></h4>
<p><span style="background: #ffff00">首先，我们导入本次所需的模块。</span></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">import tensorflow as tf</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">import numpy as np</span></code></span></font></pre><p>
<span style="background: #ffff00">构造添加一个神经层的函数。（在上次课程中有详细介绍）</span></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">def add_layer(inputs, in_size, out_size, activation_function=None):</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">Weights = tf.Variable(tf.random_normal([in_size, out_size]))</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">Wx_plus_b = tf.matmul(inputs, Weights) + biases</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">if activation_function is None:</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">        </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">outputs = Wx_plus_b</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">else:</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">        </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">outputs = activation_function(Wx_plus_b)</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">return outputs</span></code></span></font></pre><h4>
<a name="导入数据"></a><span style="background: #ffff00">导入数据</span></h4>
<p><span style="background: #ffff00">构建所需的数据。
这里的</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">x_data</span></code></span></font><span style="background: #ffff00">和</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">y_data</span></code></span></font><span style="background: #ffff00">并不是严格的一元二次函数的关系，因为我们多加了一个</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">noise</span></code><span style="background: #ffff00">,</span></span></font><span style="background: #ffff00">这样看起来会更像真实情况。</span></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">x_data = np.linspace(-1,1,300, dtype=np.float32)[:, np.newaxis]</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">noise = np.random.normal(0, 0.05, x_data.shape).astype(np.float32)</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">y_data = np.square(x_data) - 0.5 + noise</span></code></span></font></pre><p>
<span style="background: #ffff00">利用占位符定义我们所需的神经网络的输入。
</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">tf.placeholder()</span></code></span></font><span style="background: #ffff00">就是代表占位符，这里的</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">None</span></code></span></font><span style="background: #ffff00">代表无论输入有多少都可以，因为输入只有一个特征，所以这里是</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">1</span></code></span></font><span style="background: #ffff00">。</span></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">xs = tf.placeholder(tf.float32, [None, 1])</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">ys = tf.placeholder(tf.float32, [None, 1])</span></code></span></font></pre><p>
<span style="background: #ffff00">接下来，我们就可以开始定义神经层了。
通常神经层都包括输入层、隐藏层和输出层。这里的输入层只有一个属性，
所以我们就只有一个输入；隐藏层我们可以自己假设，这里我们假设隐藏层有<font face="Liberation Serif, serif"><span lang="en-US">10</span></font>个神经元；
输出层和输入层的结构是一样的，所以我们的输出层也是只有一层。
所以，我们构建的是——输入层<font face="Liberation Serif, serif"><span lang="en-US">1</span></font>个、隐藏层<font face="Liberation Serif, serif"><span lang="en-US">10</span></font>个、输出层<font face="Liberation Serif, serif"><span lang="en-US">1</span></font>个的神经网络。</span></p>
<h4><a name="搭建网络"></a><span style="background: #ffff00">搭建网络</span></h4>
<p><span style="background: #ffff00">下面，我们开始定义隐藏层<font face="Liberation Serif, serif"><span lang="en-US">,</span></font>利用之前的</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">add_layer()</span></code></span></font><span style="background: #ffff00">函数，这里使用
<font face="Liberation Serif, serif"><span lang="en-US">Tensorflow
</span></font>自带的激励函数</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">tf.nn.relu</span></code></span></font><span style="background: #ffff00">。</span></p>
<pre class="cjk" style="margin-bottom: 0.5cm"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)</span></code></span></font></pre><p>
<span style="background: #ffff00">接着，定义输出层。此时的输入就是隐藏层的输出——</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">l1</span></code></span></font><span style="background: #ffff00">，输入有<font face="Liberation Serif, serif"><span lang="en-US">10</span></font>层（隐藏层的输出层），输出有<font face="Liberation Serif, serif"><span lang="en-US">1</span></font>层。</span></p>
<pre class="cjk" style="margin-bottom: 0.5cm"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">prediction = add_layer(l1, 10, 1, activation_function=None)</span></code></span></font></pre><p>
<span style="background: #ffff00">计算预测值</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">prediction</span></code></span></font><span style="background: #ffff00">和真实值的误差，对二者差的平方求和再取平均。</span></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">                     </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">reduction_indices=[1]))</span></code></span></font></pre><p>
<span style="background: #ffff00">接下来，是很关键的一步，如何让机器学习提升它的准确率。</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">tf.train.GradientDescentOptimizer()</span></code></span></font><span style="background: #ffff00">中的值通常都小于<font face="Liberation Serif, serif"><span lang="en-US">1</span></font>，这里取的是</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">0.1</span></code></span></font><span style="background: #ffff00">，代表以</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">0.1</span></code></span></font><span style="background: #ffff00">的效率来最小化误差</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">loss</span></code></span></font><span style="background: #ffff00">。</span></p>
<pre class="cjk" style="margin-bottom: 0.5cm"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)</span></code></span></font></pre><p>
<span style="background: #ffff00">使用变量时，都要对它进行初始化，这是必不可少的。</span></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00"># init = tf.initialize_all_variables() # tf </code></span></font><code class="cjk">马上就要废弃这种写法</span></code>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">init = tf.global_variables_initializer()  # </code></span></font><code class="cjk">替换成这样就好</span></code></pre><p>
<span style="background: #ffff00">定义</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">Session</span></code></span></font><span style="background: #ffff00">，并用
</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">Session</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">来执行 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">init</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">初始化步骤。
（注意：在</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">tensorflow</span></code></span></font><span style="background: #ffff00">中，只有</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">session.run()</span></code></span></font><span style="background: #ffff00">才会执行我们定义的运算。）</span></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">sess = tf.Session()</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">sess.run(init)</span></code></span></font></pre><h4>
<a name="训练"></a><span style="background: #ffff00">训练</span></h4>
<p><span style="background: #ffff00">下面，让机器开始学习。</span></p>
<p><span style="background: #ffff00">比如这里，我们让机器学习<font face="Liberation Serif, serif"><span lang="en-US">1000</span></font>次。机器学习的内容是</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">train_step</span></code><span style="background: #ffff00">,
</span></span></font><span style="background: #ffff00">用 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">Session</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">来 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">run</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">每一次
<font face="Liberation Serif, serif"><span lang="en-US">training
</span></font>的数据，逐步提升神经网络的预测准确性。
<font face="Liberation Serif, serif"><span lang="en-US">(</span></font>注意：当运算要用到</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">placeholder</span></code></span></font><span style="background: #ffff00">时，就需要</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">feed_dict</span></code></span></font><span style="background: #ffff00">这个字典来指定输入。<font face="Liberation Serif, serif"><span lang="en-US">)</span></span></font></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">for i in range(1000):</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"># training</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">sess.run(train_step, feed_dict={xs: x_data, ys: y_data})</span></code></span></font></pre><p>
<span style="background: #ffff00">每<font face="Liberation Serif, serif"><span lang="en-US">50</span></font>步我们输出一下机器学习的误差。</span></p>
<pre class="cjk"><code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">if i % 50 == 0:</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">        </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"># to see the step improvement</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">        </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">print(sess.run(loss, feed_dict={xs: x_data, ys: y_data}))</span></code></span></font></pre><p>
<span style="background: #ffff00">在电脑上运行本次代码的结果为：</span></p>
<p><img src="data:image/png;base64,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" name="图像1" align="bottom" width="313" height="403" border="0"/>
</p>
<p><span style="background: #ffff00">通过上图可以看出，误差在逐渐减小，这说明机器学习是有积极的效果的。</span></p>
<div id="bottom-donation-section" dir="ltr">
	<p style="margin-bottom: 0cm"><br/>

	</p>
</div>
</body>
</html>
>>>>>>> dbe96efc57d6db2998967ee467c1f1106a52b1ba
