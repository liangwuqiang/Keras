<!DOCTYPE html>
    <html><head><meta charset="UTF-8">
    </head><body>
    <p><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/">原文链接</a></p>
        <div class="tut-main-content-pad">
<br>
<h1>例子3 添加层 def add_layer()</h1>
<p style="text-align: center;">
        
          作者: <strong>赵孔亚</strong>   
        
        编辑: <strong>莫烦</strong>   
        
      </p>
<p>学习资料:</p>
<ul>
<li><a href="https://github.com/MorvanZhou/tutorials/blob/master/tensorflowTUT/tensorflow10_def_add_layer.py">相关代码</a></li>
<li>为 TF 2017 打造的<a href="https://github.com/MorvanZhou/Tensorflow-Tutorial">新版可视化教学代码</a></li>
</ul>
<h4 class="tut-h4-pad" id="定义 add_layer()">定义 add_layer()</h4>
<p>在 Tensorflow 里定义一个添加层的函数可以很容易的添加神经层,为之后的添加省下不少时间.</p>
<p>神经层里常见的参数通常有<code class="highlighter-rouge">weights</code>、<code class="highlighter-rouge">biases</code>和激励函数。</p>
<p>首先，我们需要导入<code class="highlighter-rouge">tensorflow</code>模块。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
</code></pre>
</div>
<p>然后定义添加神经层的函数<code class="highlighter-rouge">def add_layer()</code>,它有四个参数：输入值、输入的大小、输出的大小和激励函数，我们设定默认的激励函数是<code class="highlighter-rouge">None</code>。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">add_layer</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">activation_function</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>    
</code></pre>
</div>
<p>接下来，我们开始定义<code class="highlighter-rouge">weights</code>和<code class="highlighter-rouge">biases</code>。</p>
<p>因为在生成初始参数时，随机变量(normal distribution)会比全部为0要好很多，所以我们这里的<code class="highlighter-rouge">weights</code>为一个<code class="highlighter-rouge">in_size</code>行, <code class="highlighter-rouge">out_size</code>列的随机变量矩阵。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">Weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">]))</span>
</code></pre>
</div>
<p>在机器学习中，<code class="highlighter-rouge">biases</code>的推荐值不为0，所以我们这里是在0向量的基础上又加了<code class="highlighter-rouge">0.1</code>。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">biases</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_size</span><span class="p">])</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
</code></pre>
</div>
<p>下面，我们定义<code class="highlighter-rouge">Wx_plus_b</code>, 即神经网络未激活的值。其中，<code class="highlighter-rouge">tf.matmul()</code>是矩阵的乘法。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">Wx_plus_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">Weights</span><span class="p">)</span> <span class="o">+</span> <span class="n">biases</span>
</code></pre>
</div>
<div>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle" data-ad-client="ca-pub-4601203457616636" data-ad-format="fluid" data-ad-layout="in-article" data-ad-slot="3397817325" style="display:block; text-align:center;"></ins>
<script>
       (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>
<p>当<code class="highlighter-rouge">activation_function</code>——激励函数为<code class="highlighter-rouge">None</code>时，输出就是当前的预测值——<code class="highlighter-rouge">Wx_plus_b</code>，不为<code class="highlighter-rouge">None</code>时，就把<code class="highlighter-rouge">Wx_plus_b</code>传到<code class="highlighter-rouge">activation_function()</code>函数中得到输出。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">if</span> <span class="n">activation_function</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">Wx_plus_b</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">activation_function</span><span class="p">(</span><span class="n">Wx_plus_b</span><span class="p">)</span>
</code></pre>
</div>
<p>最后，返回输出，添加一个神经层的函数——<code class="highlighter-rouge">def add_layer()</code>就定义好了。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">return</span> <span class="n">outputs</span>
</code></pre>
</div>
<p style="font-size: 0.8em; padding:4em 1em 0.5em 1em; margin: 0 auto;">
        如果你觉得这篇文章或视频对你的学习很有帮助, 请你也分享它, 让它能再次帮助到更多的需要学习的人.

        莫烦没有正式的经济来源, 如果你也想支持 <strong>莫烦Python</strong> 并看到更好的教学内容, 赞助他一点点, 作为鼓励他继续开源的动力.
      </p>
<!-- donation -->
<div id="bottom-donation-section">
<h3 id="bottom-donation-title">支持 让教学变得更优秀</h3>
<br>
<div>
<a href="/support/" id="bottom-donation-button"><strong>点我 赞助 莫烦</strong></a>
</div>
<br>
</br></br></div>
<hr>
</hr></br></div>
    </body></html>