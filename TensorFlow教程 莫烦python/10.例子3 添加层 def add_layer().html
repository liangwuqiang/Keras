<<<<<<< HEAD
<!DOCTYPE html>
    <html><head><meta charset="UTF-8">
    </head><body>
    <p><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/">原文链接</a></p>
        <div class="tut-main-content-pad">
<hr>
<h1>例子3 添加层 def add_layer()</h1>
<p style="text-align: center;">
        
          作者: <strong>赵孔亚</strong>   
        
        编辑: <strong>莫烦</strong>   
        
          2016-11-03
        
      </p>
<p>学习资料:</p>
<ul>
<li><a href="https://github.com/MorvanZhou/tutorials/blob/master/tensorflowTUT/tensorflow10_def_add_layer.py">相关代码</a></li>
<li>为 TF 2017 打造的<a href="https://github.com/MorvanZhou/Tensorflow-Tutorial">新版可视化教学代码</a></li>
</ul>
<h4 class="tut-h4-pad" id="定义 add_layer()">定义 add_layer()</h4>
<p>在 Tensorflow 里定义一个添加层的函数可以很容易的添加神经层,为之后的添加省下不少时间.</p>
<p>神经层里常见的参数通常有<code class="highlighter-rouge">weights</code>、<code class="highlighter-rouge">biases</code>和激励函数。</p>
<p>首先，我们需要导入<code class="highlighter-rouge">tensorflow</code>模块。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
</code></pre>
</div>
<p>然后定义添加神经层的函数<code class="highlighter-rouge">def add_layer()</code>,它有四个参数：输入值、输入的大小、输出的大小和激励函数，我们设定默认的激励函数是<code class="highlighter-rouge">None</code>。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">add_layer</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">activation_function</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>    
</code></pre>
</div>
<p>接下来，我们开始定义<code class="highlighter-rouge">weights</code>和<code class="highlighter-rouge">biases</code>。</p>
<p>因为在生成初始参数时，随机变量(normal distribution)会比全部为0要好很多，所以我们这里的<code class="highlighter-rouge">weights</code>为一个<code class="highlighter-rouge">in_size</code>行, <code class="highlighter-rouge">out_size</code>列的随机变量矩阵。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">Weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">]))</span>
</code></pre>
</div>
<p>在机器学习中，<code class="highlighter-rouge">biases</code>的推荐值不为0，所以我们这里是在0向量的基础上又加了<code class="highlighter-rouge">0.1</code>。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">biases</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_size</span><span class="p">])</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
</code></pre>
</div>
<p>下面，我们定义<code class="highlighter-rouge">Wx_plus_b</code>, 即神经网络未激活的值。其中，<code class="highlighter-rouge">tf.matmul()</code>是矩阵的乘法。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">Wx_plus_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">Weights</span><span class="p">)</span> <span class="o">+</span> <span class="n">biases</span>
</code></pre>
</div>
<p>当<code class="highlighter-rouge">activation_function</code>——激励函数为<code class="highlighter-rouge">None</code>时，输出就是当前的预测值——<code class="highlighter-rouge">Wx_plus_b</code>，不为<code class="highlighter-rouge">None</code>时，就把<code class="highlighter-rouge">Wx_plus_b</code>传到<code class="highlighter-rouge">activation_function()</code>函数中得到输出。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">if</span> <span class="n">activation_function</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">Wx_plus_b</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">activation_function</span><span class="p">(</span><span class="n">Wx_plus_b</span><span class="p">)</span>
</code></pre>
</div>
<p>最后，返回输出，添加一个神经层的函数——<code class="highlighter-rouge">def add_layer()</code>就定义好了。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">return</span> <span class="n">outputs</span>
</code></pre>
</div>
<p style="font-size: 0.8em; padding:4em 1em 0.5em 1em; margin: 0 auto;">
        如果你觉得这篇文章或视频对你的学习很有帮助, 请你也分享它, 让它能再次帮助到更多的需要学习的人.

        莫烦没有正式的经济来源, 如果你也想支持 <strong>莫烦Python</strong> 并看到更好的教学内容, 赞助他一点点, 作为鼓励他继续开源的动力.
      </p>
<!-- donation -->
<div id="bottom-donation-section">
<h3 id="bottom-donation-title">支持 让教学变得更优秀</h3>
<br>
<div>
<a href="/support/" id="bottom-donation-button"><strong>点我 赞助 莫烦</strong></a>
</div>
<br>
</br></br></div>
<hr>
</hr></hr></div>
    </body></html>
=======
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8"/>
	<title></title>
	<meta name="generator" content="LibreOffice 5.1.4.2 (Linux)"/>
	<meta name="created" content="00:00:00"/>
	<meta name="changed" content="2017-09-19T15:27:35.168357069"/>
	<meta name="" content=""/>
	<style type="text/css">
		pre.ctl { font-family: "Liberation Mono", monospace }
		code.ctl { font-family: "Liberation Mono", monospace }
	</style>
</head>
<body lang="zh-CN" dir="ltr">
<p><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/"><span style="background: #ffff00">原文链接</span></a></p>
<hr/>

<h1><span style="background: #ffff00">例子<font face="Thorndale, serif"><font size="6" style="font-size: 24pt"><span lang="en-US">3
</span></font></font>添加层 <font face="Thorndale, serif"><font size="6" style="font-size: 24pt"><span lang="en-US">def
add_layer()</span></span></font></font></h1>
<p align="center"><span style="background: #ffff00">作者<font face="Liberation Serif, serif"><span lang="en-US">:
</span></span></font><strong><span style="background: #ffff00">赵孔亚</span></strong><span style="background: #ffff00">
&nbsp;&nbsp; 编辑<font face="Liberation Serif, serif"><span lang="en-US">:
</span></span></font><strong><span style="background: #ffff00">莫烦</span></strong><span style="background: #ffff00">
&nbsp;&nbsp; <font face="Liberation Serif, serif"><span lang="en-US">2016-11-03
</span></span></font>
</p>
<p><span style="background: #ffff00">学习资料<font face="Liberation Serif, serif"><span lang="en-US">:</span></span></font></p>
<ul>
	<li/>
<p style="margin-bottom: 0cm"><span style="background: #ffff00"><a href="https://github.com/MorvanZhou/tutorials/blob/master/tensorflowTUT/tensorflow10_def_add_layer.py">相关代码</a>
	</span>
	</p>
	<li/>
<p><span style="background: #ffff00">为 <font face="Liberation Serif, serif"><span lang="en-US">TF
	2017 </span></font>打造的<a href="https://github.com/MorvanZhou/Tensorflow-Tutorial">新版可视化教学代码</a>
	</span>
	</p>
</ul>
<h4><a name="定义 add_layer()"></a><span style="background: #ffff00">定义
<font face="Liberation Serif, serif"><span lang="en-US">add_layer()</span></span></font></h4>
<p><span style="background: #ffff00">在 <font face="Liberation Serif, serif"><span lang="en-US">Tensorflow
</span></font>里定义一个添加层的函数可以很容易的添加神经层<font face="Liberation Serif, serif"><span lang="en-US">,</span></font>为之后的添加省下不少时间<font face="Liberation Serif, serif"><span lang="en-US">.</span></span></font></p>
<p><span style="background: #ffff00">神经层里常见的参数通常有</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">weights</span></code></span></font><span style="background: #ffff00">、</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">biases</span></code></span></font><span style="background: #ffff00">和激励函数。</span></p>
<p><span style="background: #ffff00">首先，我们需要导入</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">tensorflow</span></code></span></font><span style="background: #ffff00">模块。</span></p>
<pre class="cjk" style="margin-bottom: 0.5cm"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">import tensorflow as tf</span></code></span></font></pre><p>
<span style="background: #ffff00">然后定义添加神经层的函数</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">def
add_layer()</span></code><span style="background: #ffff00">,</span></span></font><span style="background: #ffff00">它有四个参数：输入值、输入的大小、输出的大小和激励函数，我们设定默认的激励函数是</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">None</span></code></span></font><span style="background: #ffff00">。</span></p>
<pre class="cjk" style="margin-bottom: 0.5cm"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">def add_layer(inputs, in_size, out_size, activation_function=None):    </span></code></span></font></pre><p>
<span style="background: #ffff00">接下来，我们开始定义</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">weights</span></code></span></font><span style="background: #ffff00">和</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">biases</span></code></span></font><span style="background: #ffff00">。</span></p>
<p><span style="background: #ffff00">因为在生成初始参数时，随机变量<font face="Liberation Serif, serif"><span lang="en-US">(normal
distribution)</span></font>会比全部为<font face="Liberation Serif, serif"><span lang="en-US">0</span></font>要好很多，所以我们这里的</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">weights</span></code></span></font><span style="background: #ffff00">为一个</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">in_size</span></code></span></font><span style="background: #ffff00">行<font face="Liberation Serif, serif"><span lang="en-US">,
</span><code class="western"><span style="background: #ffff00">out_size</span></code></span></font><span style="background: #ffff00">列的随机变量矩阵。</span></p>
<pre class="cjk" style="margin-bottom: 0.5cm"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">Weights = tf.Variable(tf.random_normal([in_size, out_size]))</span></code></span></font></pre><p>
<span style="background: #ffff00">在机器学习中，</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">biases</span></code></span></font><span style="background: #ffff00">的推荐值不为<font face="Liberation Serif, serif"><span lang="en-US">0</span></font>，所以我们这里是在<font face="Liberation Serif, serif"><span lang="en-US">0</span></font>向量的基础上又加了</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">0.1</span></code></span></font><span style="background: #ffff00">。</span></p>
<pre class="cjk" style="margin-bottom: 0.5cm"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)</span></code></span></font></pre><p>
<span style="background: #ffff00">下面，我们定义</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">Wx_plus_b</span></code><span style="background: #ffff00">,
</span></span></font><span style="background: #ffff00">即神经网络未激活的值。其中，</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">tf.matmul()</span></code></span></font><span style="background: #ffff00">是矩阵的乘法。</span></p>
<pre class="cjk" style="margin-bottom: 0.5cm"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">Wx_plus_b = tf.matmul(inputs, Weights) + biases</span></code></span></font></pre><p>
<span style="background: #ffff00">当</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">activation_function</span></code><span style="background: #ffff00">——</span></span></font><span style="background: #ffff00">激励函数为</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">None</span></code></span></font><span style="background: #ffff00">时，输出就是当前的预测值——</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">Wx_plus_b</span></code></span></font><span style="background: #ffff00">，不为</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">None</span></code></span></font><span style="background: #ffff00">时，就把</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">Wx_plus_b</span></code></span></font><span style="background: #ffff00">传到</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">activation_function()</span></code></span></font><span style="background: #ffff00">函数中得到输出。</span></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">if activation_function is None:</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">        </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">outputs = Wx_plus_b</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">else:</span></code></span></font>
<code class="cjk">        </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">outputs = activation_function(Wx_plus_b)</code></span></font></pre><p>
<span style="background: #ffff00">最后，返回输出，添加一个神经层的函数——</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">def
add_layer()</span></code></span></font><span style="background: #ffff00">就定义好了。</span></p>
<pre class="cjk" style="margin-bottom: 0.5cm"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">return outputs</span></code></span></font></pre><p>
<br/>
<br/>

</p>
</body>
</html>
>>>>>>> dbe96efc57d6db2998967ee467c1f1106a52b1ba
