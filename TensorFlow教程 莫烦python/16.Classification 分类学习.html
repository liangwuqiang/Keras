<!DOCTYPE html>
    <html><head><meta charset="UTF-8">
    </head><body>
    <p><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/">原文链接</a></p>
        <div class="tut-main-content-pad">
<hr>
<h1>Classification 分类学习</h1>
<p style="text-align: center;">
        
          作者: <strong>Mark JingNB</strong>   
        
        编辑: <strong>莫烦</strong>   
        
          2016-11-03
        
      </p>
<p>学习资料:</p>
<ul>
<li><a href="https://github.com/MorvanZhou/tutorials/tree/master/tensorflowTUT/tf16_classification">相关代码</a></li>
<li>为 TF 2017 打造的<a href="https://github.com/MorvanZhou/Tensorflow-Tutorial">新版可视化教学代码</a></li>
</ul>
<p>这次我们会介绍如何使用TensorFlow解决Classification（分类）问题。
之前的视频讲解的是Regression (回归)问题。
分类和回归的区别在于输出变量的类型上。
通俗理解定量输出是回归，或者说是连续变量预测；
定性输出是分类，或者说是离散变量预测。如预测房价这是一个回归任务；
把东西分成几类, 比如猫狗猪牛，就是一个分类任务。</p>
<h4 class="tut-h4-pad" id="MNIST 数据">MNIST 数据</h4>
<p>首先准备数据（MNIST库）</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="kn">import</span> <span class="n">input_data</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s">'MNIST_data'</span><span class="p">,</span> <span class="n">one_hot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre>
</div>
<p>MNIST库是手写体数字库，差不多是这样子的</p>
<p><img class="course-image" src="images/3fcb189934efa7ed0170baa8de700395.png"/></p>
<p>数据中包含55000张训练图片，每张图片的分辨率是28×28，所以我们的训练网络输入应该是28×28=784个像素数据。</p>
<h4 class="tut-h4-pad" id="搭建网络">搭建网络</h4>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">xs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span> <span class="c"># 28x28</span>
</code></pre>
</div>
<p>每张图片都表示一个数字，所以我们的输出是数字0到9，共10类。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">ys</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</code></pre>
</div>
<p>调用add_layer函数搭建一个最简单的训练网络结构，只有输入层和输出层。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">prediction</span> <span class="o">=</span> <span class="n">add_layer</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">activation_function</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>
</code></pre>
</div>
<p>其中输入数据是784个特征，输出数据是10个特征，激励采用softmax函数，网络结构图是这样子的</p>
<p><img class="course-image" src="images/da238782f03ad7b80c6598a29a3b4f97.png"/></p>
<h4 class="tut-h4-pad" id="Cross entropy loss">Cross entropy loss</h4>
<p>loss函数（即最优化目标函数）选用交叉熵函数。交叉熵用来衡量预测值和真实值的相似程度，如果完全相同，它们的交叉熵等于零。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">ys</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">prediction</span><span class="p">),</span>
<span class="n">reduction_indices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span> <span class="c"># loss</span>
</code></pre>
</div>
<p>train方法（最优化算法）采用梯度下降法。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">train_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cross_entropy</span><span class="p">)</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="c"># tf.initialize_all_variables() 这种写法马上就要被废弃</span>
<span class="c"># 替换成下面的写法:</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
</code></pre>
</div>
<h4 class="tut-h4-pad" id="训练">训练</h4>
<p>现在开始train，每次只取100张图片，免得数据太多训练太慢。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">batch_xs</span><span class="p">,</span> <span class="n">batch_ys</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_step</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">xs</span><span class="p">:</span> <span class="n">batch_xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">:</span> <span class="n">batch_ys</span><span class="p">})</span>
</code></pre>
</div>
<p>每训练50次输出一下预测精度</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">compute_accuracy</span><span class="p">(</span>
            <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">images</span><span class="p">,</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">labels</span><span class="p">))</span>
</code></pre>
</div>
<p>输出结果如下：</p>
<p><img class="course-image" src="images/7a195722777ed492675d1e9a62833842.png"/></p>
<p>有没有很惊讶啊，如此简单的神经网络结构竟然可以达到这样的图像识别精度，其实稍作改动后，识别的精度将大幅提高。
请关注后续课程哦。</p>
<p style="font-size: 0.8em; padding:4em 1em 0.5em 1em; margin: 0 auto;">
        如果你觉得这篇文章或视频对你的学习很有帮助, 请你也分享它, 让它能再次帮助到更多的需要学习的人.

        莫烦没有正式的经济来源, 如果你也想支持 <strong>莫烦Python</strong> 并看到更好的教学内容, 赞助他一点点, 作为鼓励他继续开源的动力.
      </p>
<!-- donation -->
<div id="bottom-donation-section">
<h3 id="bottom-donation-title">支持 让教学变得更优秀</h3>
<br>
<div>
<a href="/support/" id="bottom-donation-button"><strong>点我 赞助 莫烦</strong></a>
</div>
<br>
</br></br></div>
<hr>
</hr></hr></div>
    </body></html>