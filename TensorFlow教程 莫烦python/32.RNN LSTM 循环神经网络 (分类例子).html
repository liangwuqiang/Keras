<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8"/>
	<title></title>
	<meta name="generator" content="LibreOffice 5.1.6.2 (Linux)"/>
	<meta name="created" content="00:00:00"/>
	<meta name="changed" content="2017-09-29T14:29:37.041968030"/>
	<meta name="" content=""/>
	<style type="text/css">
		pre.ctl { font-family: "Liberation Mono", monospace }
		code.ctl { font-family: "Liberation Mono", monospace }
	</style>
</head>
<body lang="zh-CN" dir="ltr">
<p><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/"><span style="background: #ffff00">原文链接</span></a></p>
<p><br/>
<br/>

</p>
<h1><font face="Thorndale, serif"><font size="6" style="font-size: 24pt"><span lang="en-US"><span style="background: #ffff00">RNN
LSTM </span></font></font>循环神经网络 <font face="Thorndale, serif"><font size="6" style="font-size: 24pt"><span lang="en-US">(</span></font></font>分类例子<font face="Thorndale, serif"><font size="6" style="font-size: 24pt"><span lang="en-US">)</span></span></font></font></h1>
<p align="center"><span style="background: #ffff00">作者<font face="Liberation Serif, serif"><span lang="en-US">:
</span></span></font><strong><span style="background: #ffff00">莫烦</span></strong><span style="background: #ffff00">
&nbsp;&nbsp; 编辑<font face="Liberation Serif, serif"><span lang="en-US">:
</span></span></font><strong><span style="background: #ffff00">莫烦</span></strong><span style="background: #ffff00">
&nbsp;&nbsp; </span>
</p>
<p><span style="background: #ffff00">学习资料<font face="Liberation Serif, serif"><span lang="en-US">:</span></span></font></p>
<ul>
	<li/>
<p style="margin-bottom: 0cm"><span style="background: #ffff00"><a href="https://github.com/MorvanZhou/tutorials/tree/master/tensorflowTUT/tf20_RNN2">相关代码</a>
	</span>
	</p>
	<li/>
<p style="margin-bottom: 0cm"><span style="background: #ffff00">为
	<font face="Liberation Serif, serif"><span lang="en-US">TF 2017
	</span></font>打造的<a href="https://github.com/MorvanZhou/Tensorflow-Tutorial">新版可视化教学代码</a>
	</span>
	</p>
	<li/>
<p style="margin-bottom: 0cm"><span style="background: #ffff00">机器学习<font face="Liberation Serif, serif"><span lang="en-US">-</span></font>简介系列
	<a href="/tutorials/machine-learning/ML-intro/2-3-RNN/">什么是<font face="Liberation Serif, serif"><span lang="en-US">RNN</a>
	</span></span></font>
	</p>
	<li/>
<p style="margin-bottom: 0cm"><span style="background: #ffff00">机器学习<font face="Liberation Serif, serif"><span lang="en-US">-</span></font>简介系列
	<a href="/tutorials/machine-learning/ML-intro/2-4-LSTM/">什么是<font face="Liberation Serif, serif"><span lang="en-US">LSTM
	RNN</a> </span></span></font>
	</p>
	<li/>
<p><span style="background: #ffff00">本代码基于网上这一份代码
	<font face="Liberation Serif, serif"><span lang="en-US"><a href="https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py">code</a>
	</span></span></font>
	</p>
</ul>
<h4><a name="设置 RNN 的参数"></a><span style="background: #ffff00">设置
<font face="Liberation Serif, serif"><span lang="en-US">RNN </span></font>的参数</span></h4>
<p><span style="background: #ffff00">这次我们会使用 <font face="Liberation Serif, serif"><span lang="en-US">RNN
</span></font>来进行分类的训练 <font face="Liberation Serif, serif"><span lang="en-US">(Classification).
</span></font>会继续使用到手写数字 <font face="Liberation Serif, serif"><span lang="en-US">MNIST
</span></font>数据集<font face="Liberation Serif, serif"><span lang="en-US">.</span>
</span></font><span style="background: #ffff00">让 <font face="Liberation Serif, serif"><span lang="en-US">RNN
</span></font>从每张图片的第一行像素读到最后一行<font face="Liberation Serif, serif"><span lang="en-US">,
</span></font>然后再进行分类判断<font face="Liberation Serif, serif"><span lang="en-US">.
</span></font>接下来我们导入 <font face="Liberation Serif, serif"><span lang="en-US">MNIST
</span></font>数据并确定 <font face="Liberation Serif, serif"><span lang="en-US">RNN
</span></font>的各种参数<font face="Liberation Serif, serif"><span lang="en-US">(hyper-parameters):</span></span></font></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">import tensorflow as tf</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">from tensorflow.examples.tutorials.mnist import input_data</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">tf.set_random_seed(1)   # set random seed</span></code></span></font>

<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00"># </code></span></font><code class="cjk">导入数据</span></code>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">mnist = input_data.read_data_sets('MNIST_data', one_hot=True)</span></code></span></font>

<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00"># hyperparameters</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">lr = 0.001                  # learning rate</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">training_iters = 100000     # train step </code></span></font><code class="cjk">上限</span></code>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">batch_size = 128            </span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">n_inputs = 28               # MNIST data input (img shape: 28*28)</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">n_steps = 28                # time steps</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">n_hidden_units = 128        # neurons in hidden layer</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">n_classes = 10              # MNIST classes (0-9 digits)</span></code></span></font></pre><p>
<span style="background: #ffff00">接着定义 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">x</span></code><span style="background: #ffff00">,
</span><code class="western"><span style="background: #ffff00">y</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">的
</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">placeholder</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">和 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">weights</span></code><span style="background: #ffff00">,
</span><code class="western"><span style="background: #ffff00">biases</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">的初始状况<font face="Liberation Serif, serif"><span lang="en-US">.</span></span></font></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00"># x y placeholder</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">x = tf.placeholder(tf.float32, [None, n_steps, n_inputs])</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">y = tf.placeholder(tf.float32, [None, n_classes])</span></code></span></font>

<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00"># </code></span></font><code class="cjk">对 </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">weights biases </code></span></font><code class="cjk">初始值的定义</span></code>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">weights = {</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"># shape (28, 128)</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">'in': tf.Variable(tf.random_normal([n_inputs, n_hidden_units])),</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"># shape (128, 10)</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">'out': tf.Variable(tf.random_normal([n_hidden_units, n_classes]))</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">}</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">biases = {</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"># shape (128, )</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">'in': tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ])),</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"># shape (10, )</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">'out': tf.Variable(tf.constant(0.1, shape=[n_classes, ]))</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">}</span></code></span></font></pre><h4>
<a name="定义 RNN 的主体结构"></a><span style="background: #ffff00">定义
<font face="Liberation Serif, serif"><span lang="en-US">RNN </span></font>的主体结构</span></h4>
<p><span style="background: #ffff00">接着开始定义 <font face="Liberation Serif, serif"><span lang="en-US">RNN
</span></font>主体结构<font face="Liberation Serif, serif"><span lang="en-US">,
</span></font>这个 <font face="Liberation Serif, serif"><span lang="en-US">RNN
</span></font>总共有 <font face="Liberation Serif, serif"><span lang="en-US">3
</span></font>个组成部分 <font face="Liberation Serif, serif"><span lang="en-US">(
</span><code class="western"><span style="background: #ffff00">input_layer</span></code><span style="background: #ffff00">,
</span><code class="western"><span style="background: #ffff00">cell</span></code><span style="background: #ffff00">,</span>
<code class="western"><span style="background: #ffff00">output_layer</span></code><span style="background: #ffff00">).
</span></span></font><span style="background: #ffff00">首先我们先定义
</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">input_layer</span></code><span style="background: #ffff00">:</span></span></font></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">def RNN(X, weights, biases):</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"># </code></span></font><code class="cjk">原始的 </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">X </code></span></font><code class="cjk">是 </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">3 </code></span></font><code class="cjk">维数据</code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">, </code></span></font><code class="cjk">我们需要把它变成 </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">2 </code></span></font><code class="cjk">维数据才能使用 </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">weights </code></span></font><code class="cjk">的矩阵乘法</span></code>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"># X ==&gt; (128 batches * 28 steps, 28 inputs)</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">X = tf.reshape(X, [-1, n_inputs])</span></code></span></font>

<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"># X_in = W*X + b</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">X_in = tf.matmul(X, weights['in']) + biases['in']</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"># X_in ==&gt; (128 batches, 28 steps, 128 hidden) </code></span></font><code class="cjk">换回</code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">3</code></span></font><code class="cjk">维</span></code>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">X_in = tf.reshape(X_in, [-1, n_steps, n_hidden_units])</span></code></span></font></pre><p>
<span style="background: #ffff00">接着是 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">cell</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">中的计算<font face="Liberation Serif, serif"><span lang="en-US">,
</span></font>有两种途径<font face="Liberation Serif, serif"><span lang="en-US">:</span></span></font></p>
<ol>
	<li/>
<p style="margin-bottom: 0cm"><span style="background: #ffff00">使用
	</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">tf.nn.rnn(cell,
	inputs)</span></code><span style="background: #ffff00"> (</span></span></font><span style="background: #ffff00">不推荐<a href="http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/">原因</a><font face="Liberation Serif, serif"><span lang="en-US">).
	</span></font>但是如果使用这种方法<font face="Liberation Serif, serif"><span lang="en-US">,
	</span></font>可以参考<a href="https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py">这个代码</a><font face="Liberation Serif, serif"><span lang="en-US">;
	</span></span></font>
	</p>
	<li/>
<p><span style="background: #ffff00">使用
	</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">tf.nn.dynamic_rnn(cell,
	inputs)</span></code><span style="background: #ffff00"> (</span></span></font><span style="background: #ffff00">推荐<font face="Liberation Serif, serif"><span lang="en-US">).
	</span></font>这次的练习将使用这种方式<font face="Liberation Serif, serif"><span lang="en-US">.
	</span></span></font>
	</p>
</ol>
<p><span style="background: #ffff00">因 <font face="Liberation Serif, serif"><span lang="en-US">Tensorflow
</span></font>版本升级原因<font face="Liberation Serif, serif"><span lang="en-US">,
</span><code class="western"><span style="background: #ffff00">state_is_tuple=True</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">将在之后的版本中变为默认<font face="Liberation Serif, serif"><span lang="en-US">.
</span></font>对于 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">lstm</span></code>
</span></font><span style="background: #ffff00">来说<font face="Liberation Serif, serif"><span lang="en-US">,
</span><code class="western"><span style="background: #ffff00">state</span></code></span></font><span style="background: #ffff00">可被分为</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">(c_state,
h_state)</span></code><span style="background: #ffff00">.</span></span></font></p>
<pre class="cjk"><code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"># </code></span></font><code class="cjk">使用 </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">basic LSTM Cell.</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_units, forget_bias=1.0,</span></code><code class="western"> </code><code class="western"><span style="background: #ffff00">state_is_tuple=True)</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">init_state = lstm_cell.zero_state(batch_size, dtype=tf.float32) # </code></span></font><code class="cjk">初始化全零 </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">state</span></code></span></font></pre><p>
<span style="background: #ffff00">如果使用</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">tf.nn.dynamic_rnn(cell,
inputs)</span></code><span style="background: #ffff00">, </span></span></font><span style="background: #ffff00">我们要确定
</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">inputs</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">的格式<font face="Liberation Serif, serif"><span lang="en-US">.</span>
<code class="western"><span style="background: #ffff00">tf.nn.dynamic_rnn</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">中的
</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">time_major</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">参数会针对不同
</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">inputs</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">格式有不同的值<font face="Liberation Serif, serif"><span lang="en-US">.</span></span></font></p>
<ol>
	<li/>
<p style="margin-bottom: 0cm"><span style="background: #ffff00">如果
	</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">inputs</span></code><span style="background: #ffff00">
	</span></span></font><span style="background: #ffff00">为 <font face="Liberation Serif, serif"><span lang="en-US">(batches,
	steps, inputs) ==&gt; </span><code class="western"><span style="background: #ffff00">time_major=False</span></code><span style="background: #ffff00">;
	</span></span></font>
	</p>
	<li/>
<p><span style="background: #ffff00">如果 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">inputs</span></code><span style="background: #ffff00">
	</span></span></font><span style="background: #ffff00">为 <font face="Liberation Serif, serif"><span lang="en-US">(steps,
	batches, inputs) ==&gt; </span><code class="western"><span style="background: #ffff00">time_major=True</span></code><span style="background: #ffff00">;
	</span></span></font>
	</p>
</ol>
<pre class="cjk" style="margin-bottom: 0.5cm"><code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">outputs, final_state = tf.nn.dynamic_rnn(lstm_cell, X_in,</span></code><code class="western"> </code><code class="western"><span style="background: #ffff00">initial_state=init_state, time_major=False)</span></code></span></font></pre><p>
<span style="background: #ffff00">最后是 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">output_layer</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">和 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">return</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">的值<font face="Liberation Serif, serif"><span lang="en-US">.
</span></font>因为这个例子的特殊性<font face="Liberation Serif, serif"><span lang="en-US">,
</span></font>有两种方法可以求得 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">results</span></code><span style="background: #ffff00">.</span></span></font></p>
<p><strong><span style="background: #ffff00"><script src="smb://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>
       (adsbygoogle = window.adsbygoogle || []).push({});
  

</script>方式一<font face="Liberation Serif, serif"><span lang="en-US">:</span></strong><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">直接调用</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">final_state</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">中的 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">h_state</span></code><span style="background: #ffff00">
(</span><code class="western"><span style="background: #ffff00">final_state[1]</span></code><span style="background: #ffff00">)
</span></span></font><span style="background: #ffff00">来进行运算<font face="Liberation Serif, serif"><span lang="en-US">:</span></span></font></p>
<pre class="cjk" style="margin-bottom: 0.5cm"><code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">results = tf.matmul(final_state[1], weights['out']) + biases['out']</span></code></span></font></pre><p>
<strong><span style="background: #ffff00">方式二<font face="Liberation Serif, serif"><span lang="en-US">:</span></strong><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">调用最后一个
</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">outputs</span></code><span style="background: #ffff00">
(</span></span></font><span style="background: #ffff00">在这个例子中<font face="Liberation Serif, serif"><span lang="en-US">,</span></font>和上面的</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">final_state[1]</span></code></span></font><span style="background: #ffff00">是一样的<font face="Liberation Serif, serif"><span lang="en-US">):</span></span></font></p>
<pre class="cjk"><code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"># </code></span></font><code class="cjk">把 </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">outputs </code></span></font><code class="cjk">变成 列表 </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">[(batch, outputs)..] * steps</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">outputs = tf.unstack(tf.transpose(outputs, [1,0,2]))</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">results = tf.matmul(outputs[-1], weights['out']) + biases['out']    #</code></span></font><code class="cjk">选取最后一个</span></code><code class="cjk"> </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">output</span></code></span></font></pre><p>
<span style="background: #ffff00">在 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">def
RNN()</span></code><span style="background: #ffff00"> </span></span></font><span style="background: #ffff00">的最后输出
</span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">result</span></code></span></font></p>
<pre class="cjk" style="margin-bottom: 0.5cm"><code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">return results</span></code></span></font></pre><p>
<span style="background: #ffff00">定义好了 <font face="Liberation Serif, serif"><span lang="en-US">RNN
</span></font>主体结构后<font face="Liberation Serif, serif"><span lang="en-US">,
</span></font>我们就可以来计算 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">cost</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">和 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">train_op</span></code><span style="background: #ffff00">:</span></span></font></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">pred = RNN(x, weights, biases)</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">train_op = tf.train.AdamOptimizer(lr).minimize(cost)</span></code></span></font></pre><h4>
<a name="训练 RNN"></a><span style="background: #ffff00">训练 <font face="Liberation Serif, serif"><span lang="en-US">RNN</span></span></font></h4>
<p><span style="background: #ffff00">训练时<font face="Liberation Serif, serif"><span lang="en-US">,
</span></font>不断输出 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">accuracy</span></code><span style="background: #ffff00">,
</span></span></font><span style="background: #ffff00">观看结果<font face="Liberation Serif, serif"><span lang="en-US">:</span></span></font></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span></code></span></font>

<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00"># init= tf.initialize_all_variables() # tf </code></span></font><code class="cjk">马上就要废弃这种写法</span></code>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00"># </code></span></font><code class="cjk">替换成下面的写法</code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">:</span></code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">init = tf.global_variables_initializer()</span></code></span></font>

<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western"><span style="background: #ffff00">with tf.Session() as sess:</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">sess.run(init)</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">step = 0</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">    </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">while step * batch_size &lt; training_iters:</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">        </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">        </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">batch_xs = batch_xs.reshape([batch_size, n_steps, n_inputs])</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">        </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">sess.run([train_op], feed_dict={</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">            </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">x: batch_xs,</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">            </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">y: batch_ys,</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">        </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">})</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">        </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">if step % 20 == 0:</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">            </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">print(sess.run(accuracy, feed_dict={</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">            </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">x: batch_xs,</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">            </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">y: batch_ys,</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">        </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">}))</span></code></span></font>
<code class="cjk"><span style="background: #ffff00">        </code><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">step += 1</span></code></span></font></pre><p>
<span style="background: #ffff00">最终 </span><font face="Liberation Serif, serif"><span lang="en-US"><code class="western"><span style="background: #ffff00">accuracy</span></code><span style="background: #ffff00">
</span></span></font><span style="background: #ffff00">的结果如下<font face="Liberation Serif, serif"><span lang="en-US">:</span></span></font></p>
<pre class="cjk"><font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.1875</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.65625</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.726562</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.757812</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.820312</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.796875</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.859375</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.921875</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.921875</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.898438</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.828125</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.890625</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.9375</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.921875</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.9375</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.929688</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">0.953125</code></span></font>
<font face="Liberation Mono, monospace"><span lang="en-US"><code class="western">....</code></span></font></pre><p>
<br/>
<br/>

</p>
</body>
</html>