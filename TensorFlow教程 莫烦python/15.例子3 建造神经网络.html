<!DOCTYPE html>
    <html><head><meta charset="UTF-8">
    </head><body>
    <p><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/">原文链接</a></p>
        <div class="tut-main-content-pad">
<br>
<h1>例子3 建造神经网络</h1>
<p style="text-align: center;">
        
          作者: <strong>赵孔亚</strong>   
        
        编辑: <strong>莫烦</strong>   
        
      </p>
<p>学习资料:</p>
<ul>
<li><a href="https://github.com/MorvanZhou/tutorials/blob/master/tensorflowTUT/tensorflow11_build_network.py">相关代码</a></li>
<li>为 TF 2017 打造的<a href="https://github.com/MorvanZhou/Tensorflow-Tutorial">新版可视化教学代码</a></li>
</ul>
<p>这次提到了怎样建造一个完整的神经网络,包括添加神经层,计算误差,训练步骤,判断是否在学习.</p>
<p>本次课程，我们会在上节课的基础上，继续讲解如何构建神经层。</p>
<h4 class="tut-h4-pad" id="add_layer 功能">add_layer 功能</h4>
<p>首先，我们导入本次所需的模块。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</code></pre>
</div>
<p>构造添加一个神经层的函数。（在上次课程中有详细介绍）</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">add_layer</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">activation_function</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">Weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">]))</span>
    <span class="n">biases</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_size</span><span class="p">])</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">Wx_plus_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">Weights</span><span class="p">)</span> <span class="o">+</span> <span class="n">biases</span>
    <span class="k">if</span> <span class="n">activation_function</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">Wx_plus_b</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">activation_function</span><span class="p">(</span><span class="n">Wx_plus_b</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span>
</code></pre>
</div>
<h4 class="tut-h4-pad" id="导入数据">导入数据</h4>
<p>构建所需的数据。
这里的<code class="highlighter-rouge">x_data</code>和<code class="highlighter-rouge">y_data</code>并不是严格的一元二次函数的关系，因为我们多加了一个<code class="highlighter-rouge">noise</code>,这样看起来会更像真实情况。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">300</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">x_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="n">noise</span>
</code></pre>
</div>
<p>利用占位符定义我们所需的神经网络的输入。
<code class="highlighter-rouge">tf.placeholder()</code>就是代表占位符，这里的<code class="highlighter-rouge">None</code>代表无论输入有多少都可以，因为输入只有一个特征，所以这里是<code class="highlighter-rouge">1</code>。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">xs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</code></pre>
</div>
<p>接下来，我们就可以开始定义神经层了。
通常神经层都包括输入层、隐藏层和输出层。这里的输入层只有一个属性，
所以我们就只有一个输入；隐藏层我们可以自己假设，这里我们假设隐藏层有10个神经元；
输出层和输入层的结构是一样的，所以我们的输出层也是只有一层。
所以，我们构建的是——输入层1个、隐藏层10个、输出层1个的神经网络。</p>
<div>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle" data-ad-client="ca-pub-4601203457616636" data-ad-format="fluid" data-ad-layout="in-article" data-ad-slot="3397817325" style="display:block; text-align:center;"></ins>
<script>
       (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>
<h4 class="tut-h4-pad" id="搭建网络">搭建网络</h4>
<p>下面，我们开始定义隐藏层,利用之前的<code class="highlighter-rouge">add_layer()</code>函数，这里使用 Tensorflow 自带的激励函数<code class="highlighter-rouge">tf.nn.relu</code>。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">l1</span> <span class="o">=</span> <span class="n">add_layer</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">activation_function</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
</code></pre>
</div>
<p>接着，定义输出层。此时的输入就是隐藏层的输出——<code class="highlighter-rouge">l1</code>，输入有10层（隐藏层的输出层），输出有1层。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">prediction</span> <span class="o">=</span> <span class="n">add_layer</span><span class="p">(</span><span class="n">l1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">activation_function</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</code></pre>
</div>
<p>计算预测值<code class="highlighter-rouge">prediction</code>和真实值的误差，对二者差的平方求和再取平均。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">ys</span> <span class="o">-</span> <span class="n">prediction</span><span class="p">),</span>
                     <span class="n">reduction_indices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</code></pre>
</div>
<p>接下来，是很关键的一步，如何让机器学习提升它的准确率。<code class="highlighter-rouge">tf.train.GradientDescentOptimizer()</code>中的值通常都小于1，这里取的是<code class="highlighter-rouge">0.1</code>，代表以<code class="highlighter-rouge">0.1</code>的效率来最小化误差<code class="highlighter-rouge">loss</code>。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">train_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</code></pre>
</div>
<p>使用变量时，都要对它进行初始化，这是必不可少的。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># init = tf.initialize_all_variables() # tf 马上就要废弃这种写法</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>  <span class="c"># 替换成这样就好</span>
</code></pre>
</div>
<p>定义<code class="highlighter-rouge">Session</code>，并用 <code class="highlighter-rouge">Session</code> 来执行 <code class="highlighter-rouge">init</code> 初始化步骤。
（注意：在<code class="highlighter-rouge">tensorflow</code>中，只有<code class="highlighter-rouge">session.run()</code>才会执行我们定义的运算。）</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
</code></pre>
</div>
<h4 class="tut-h4-pad" id="训练">训练</h4>
<p>下面，让机器开始学习。</p>
<p>比如这里，我们让机器学习1000次。机器学习的内容是<code class="highlighter-rouge">train_step</code>, 用 <code class="highlighter-rouge">Session</code> 来 <code class="highlighter-rouge">run</code> 每一次 training 的数据，逐步提升神经网络的预测准确性。
(注意：当运算要用到<code class="highlighter-rouge">placeholder</code>时，就需要<code class="highlighter-rouge">feed_dict</code>这个字典来指定输入。)</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="c"># training</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_step</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">xs</span><span class="p">:</span> <span class="n">x_data</span><span class="p">,</span> <span class="n">ys</span><span class="p">:</span> <span class="n">y_data</span><span class="p">})</span>
</code></pre>
</div>
<p>每50步我们输出一下机器学习的误差。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code>    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c"># to see the step improvement</span>
        <span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">xs</span><span class="p">:</span> <span class="n">x_data</span><span class="p">,</span> <span class="n">ys</span><span class="p">:</span> <span class="n">y_data</span><span class="p">}))</span>
</code></pre>
</div>
<p>在电脑上运行本次代码的结果为：</p>
<p><img alt="例子3 建造神经网络729" class="course-image" src="images/640ea5de8980dcb59937ab83b4c752aa.png"/></p>
<p>通过上图可以看出，误差在逐渐减小，这说明机器学习是有积极的效果的。</p>
<p style="font-size: 0.8em; padding:4em 1em 0.5em 1em; margin: 0 auto;">
        如果你觉得这篇文章或视频对你的学习很有帮助, 请你也分享它, 让它能再次帮助到更多的需要学习的人.

        莫烦没有正式的经济来源, 如果你也想支持 <strong>莫烦Python</strong> 并看到更好的教学内容, 赞助他一点点, 作为鼓励他继续开源的动力.
      </p>
<!-- donation -->
<div id="bottom-donation-section">
<h3 id="bottom-donation-title">支持 让教学变得更优秀</h3>
<br>
<div>
<a href="/support/" id="bottom-donation-button"><strong>点我 赞助 莫烦</strong></a>
</div>
<br>
</br></br></div>
<hr>
</hr></br></div>
    </body></html>