<!DOCTYPE html>
    <html><head><meta charset="UTF-8">
    </head><body>
    <p><a href="https://morvanzhou.github.io/tutorials/machine-learning/keras/">原文链接</a></p>
        <div class="tut-main-content-pad">
<hr>
<h1>Autoencoder 自编码</h1>
<p style="text-align: center;">
        
          作者: <strong>Alice</strong>   
        
        编辑: <strong>莫烦</strong>   
        
          2016-10-30
        
      </p>
<p>学习资料:</p>
<ul>
<li><a href="https://github.com/MorvanZhou/tutorials/blob/master/kerasTUT/9-Autoencoder_example.py">代码链接</a></li>
<li>机器学习-简介系列 <a href="/tutorials/machine-learning/ML-intro/2-5-autoencoder/">自编码 Autoencoder</a></li>
</ul>
<p>自编码，简单来说就是把输入数据进行一个压缩和解压缩的过程。
原来有很多 Feature，压缩成几个来代表原来的数据，解压之后恢复成原来的维度，再和原数据进行比较。</p>
<p>它是一种非监督算法，只需要输入数据，解压缩之后的结果与原数据本身进行比较。</p>
<p>今天要做的事情是把 <code class="highlighter-rouge">datasets.mnist</code> 数据的 28×28＝784 维的数据，压缩成 2 维的数据，然后在一个二维空间中可视化出分类的效果。</p>
<h4 class="tut-h4-pad" id="导入模块并创建数据">导入模块并创建数据</h4>
<p>数据仍然用 <code class="highlighter-rouge">datasets.mnist</code>。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1337</span><span class="p">)</span>  <span class="c"># for reproducibility</span>

<span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Input</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c"># download the mnist to the path '~/.keras/datasets/' if it is the first time to be called</span>
<span class="c"># X shape (60,000 28x28), y shape (10,000, )</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">_</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c"># data pre-processing</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float32'</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span> <span class="o">-</span> <span class="mf">0.5</span>       <span class="c"># minmax_normalized</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float32'</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span> <span class="o">-</span> <span class="mf">0.5</span>         <span class="c"># minmax_normalized</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>


<span class="s">"""
(60000, 784)
(10000, 784)
"""</span>
</code></pre>
</div>
<h4 class="tut-h4-pad" id="建立模型">建立模型</h4>
<p><code class="highlighter-rouge">encoding_dim</code>，要压缩成的维度。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># in order to plot in a 2D figure</span>
<span class="n">encoding_dim</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c"># this is our input placeholder</span>
<span class="n">input_img</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,))</span>
</code></pre>
</div>
<p>接下来是建立 <code class="highlighter-rouge">encoded</code> 和 <code class="highlighter-rouge">decoded</code> ，再用 <code class="highlighter-rouge">autoencoder</code> 把二者组建在一起。训练时用 <code class="highlighter-rouge">autoencoder</code>。</p>
<p><code class="highlighter-rouge">encoded</code> 用4层 <code class="highlighter-rouge">Dense</code> 全联接层，激活函数用 <code class="highlighter-rouge">relu</code>，输入的维度就是前一步定义的 <code class="highlighter-rouge">input_img</code>。</p>
<p>接下来定义下一层，它的输出维度是64，输入是上一层的输出结果。</p>
<p>在最后一层，我们定义它的输出维度就是想要的 <code class="highlighter-rouge">encoding_dim＝2</code>。</p>
<p>解压的环节，它的过程和压缩的过程是正好相反的。相对应层的激活函数也是一样的，不过在解压的最后一层用到的激活函数是 <code class="highlighter-rouge">tanh</code>。
因为输入值是由 -0.5 到 0.5 这个范围，在最后一层用这个激活函数的时候，它的输出是 -1 到 1，可以是作为一个很好的对应。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code>
<span class="c"># encoder layers</span>
<span class="n">encoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">input_img</span><span class="p">)</span>
<span class="n">encoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>
<span class="n">encoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>
<span class="n">encoder_output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">encoding_dim</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>

<span class="c"># decoder layers</span>
<span class="n">decoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">encoder_output</span><span class="p">)</span>
<span class="n">decoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">decoded</span><span class="p">)</span>
<span class="n">decoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">decoded</span><span class="p">)</span>
<span class="n">decoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'tanh'</span><span class="p">)(</span><span class="n">decoded</span><span class="p">)</span>

<span class="c"># construct the autoencoder model</span>
<span class="n">autoencoder</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">input_img</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">decoded</span><span class="p">)</span>
</code></pre>
</div>
<p>接下来直接用 <code class="highlighter-rouge">Model</code> 这个模块来组建模型，输入就是图片，输出是解压的最后的结果。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># construct the encoder model for plotting</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">input_img</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">encoder_output</span><span class="p">)</span>
</code></pre>
</div>
<p>当我们想要看由 784 压缩到 2维后，这个结果是什么样的时候，也可以只单独组建压缩的板块，此时它的输入是图片，输出是压缩环节的最后结果。</p>
<h4 class="tut-h4-pad" id="激活模型">激活模型</h4>
<p>接下来是编译自编码这个模型，优化器用的是 <code class="highlighter-rouge">adam</code>，损失函数用的是 <code class="highlighter-rouge">mse</code>。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># compile autoencoder</span>
<span class="n">autoencoder</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'mse'</span><span class="p">)</span>
</code></pre>
</div>
<h4 class="tut-h4-pad" id="训练模型">训练模型</h4>
<p>接下来训练自编码模型，注意它的输入和输出是一样的，都是训练集的 X。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># training</span>
<span class="n">autoencoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span>
                <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="s">"""
Epoch 20/20
60000/60000 [==============================] - 7s - loss: 0.0398
"""</span>
</code></pre>
</div>
<h4 class="tut-h4-pad" id="可视化结果">可视化结果</h4>
<p>最后看到可视化的结果，自编码模型可以把这几个数字给区分开来，我们可以用自编码这个过程来作为一个特征压缩的方法，和PCA的功能一样，效果要比它好一些，因为它是非线性的结构。</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># plotting</span>
<span class="n">encoded_imgs</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">encoded_imgs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">encoded_imgs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>
<p><img class="course-image" src="images/a44823216cbb33f018bc1b20dc08ba84.png"/></p>
<p style="font-size: 0.8em; padding:4em 1em 0.5em 1em; margin: 0 auto;">
        如果你觉得这篇文章或视频对你的学习很有帮助, 请你也分享它, 让它能再次帮助到更多的需要学习的人.

        莫烦没有正式的经济来源, 如果你也想支持 <strong>莫烦Python</strong> 并看到更好的教学内容, 赞助他一点点, 作为鼓励他继续开源的动力.
      </p>
<!-- donation -->
<div id="bottom-donation-section">
<h3 id="bottom-donation-title">支持 让教学变得更优秀</h3>
<br>
<div>
<a href="/support/" id="bottom-donation-button"><strong>点我 赞助 莫烦</strong></a>
</div>
<br>
</br></br></div>
<hr>
</hr></hr></div>
    </body></html>