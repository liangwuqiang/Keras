<!DOCTYPE html>
    <html><head><meta charset="UTF-8">
    </head><body>
    <p><a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/">原文链接</a></p>
        <div class="markdown-body">
<!-- 欢迎成为极客学院WIKI作者 -->
<!-- 极客学院团队出品 -->
<p class="author">极客学院团队出品 · 更新于 2017-10-13 11:00:26</p>
<!-- 内容 -->
<h1>常见问题 <a class="md-anchor" id="AUTOGENERATED-frequently-asked-questions"></a></h1>
<p>此文档对关于TensorFlow的一些常见问题提供了答案，如果这里没有你问题的答案，你可能会在<a href="tensorflow-zh/SOURCE/resoreces/index.html">社区资源</a>中找到它。</p>
<!-- TOC-BEGIN This section is generated by neural network: DO NOT EDIT! -->
<h2 id="2d711b09bd0db0ad240cc83b30dd8014">内容</h2>
<h3><a href="#AUTOGENERATED-frequently-asked-questions">常见问题</a></h3>
<ul>
<li><a href="#AUTOGENERATED-building-a-tensorflow-graph">建立 TensorFlow graph</a></li>
<li><a href="#AUTOGENERATED-running-a-tensorflow-computation">运行 TensorFlow 计算过程</a></li>
<li><a href="#AUTOGENERATED-variables">Variables</a></li>
<li><a href="#AUTOGENERATED-tensor-shapes">Tensor shapes</a></li>
<li><a href="#AUTOGENERATED-tensorboard">TensorBoard</a></li>
<li><a href="#AUTOGENERATED-extending-tensorflow">扩展 TensorFlow</a></li>
<li><a href="#AUTOGENERATED-miscellaneous">其他问题</a></li>
</ul>
<!-- TOC-END This section was generated by neural network, THANKS FOR READING! -->
<h2 id="ca32e68d4f36836fc6c93ab20ebd7293">建立 TensorFlow graph <a class="md-anchor" id="AUTOGENERATED-building-a-tensorflow-graph"></a></h2>
<p>参看
<a href="../api_docs/python/framework.html">建立 graph 的 API 文档</a>.</p>
<h4>为什么<code>c = tf.matmul(a, b)</code> 不立即执行矩阵相乘？ <a class="md-anchor" id="AUTOGENERATED-why-does--c---tf.matmul-a--b---not-execute-the-matrix-multiplication-immediately-"></a></h4>
<p>在 TensorFlow 的 Python API 中, <code>a</code>, <code>b</code>, and <code>c</code> 都是
<a #tensor="" href="../api_docs/python/framework.html"><code>Tensor</code></a> 对象. 一个 <code>Tensor</code> 对象是一个操作(operation)结果的字符别名,它实际上并不储存操作(operation)输出结果的值。
TensorFlow 鼓励用户去建立复杂的表达式（如整个神经网络及其梯度）来形成 data flow graph 。
然后你可以将整个 data flow graph 的计算过程交给一个 TensorFlow 的 <a #session="" href="../api_docs/python/client.html"><code>Session</code></a>,
此 <code>Session</code> 可以运行整个计算过程，比起操作(operations)一条一条的执行效率高的多。</p>
<h4>设备是如何命名的? <a class="md-anchor" id="AUTOGENERATED-how-are-devices-named-"></a></h4>
<p>对CPU设备而言，支持的设备名是<code>"/device:CPU:0"</code> (或 <code>"/cup:0"</code>)，对第 <em>i</em> 个 GPU 设备是<code>"/device:GPU:i"</code> (或 <code>"/gpu:i"</code>)</p>
<h4>如何在指定的设备上运行操作(operations)？ <a class="md-anchor" id="AUTOGENERATED-how-do-i-place-operations-on-a-particular-device-"></a></h4>
<p>在 <a #device="" href="../api_docs/python/framework.html"><code>with tf.device(name):</code></a> context 中创建操作(operation)，这样可以在指定的设备上运行操作(operation)。
关于 TensorFlow 怎样将操作(operations)分配给设备的细节，参看 <a href="../how_tos/using_gpu/index.html">TensorFlow使用 GPU </a>; 使用多 GPU 的示范实例参看 <a href="../tutorials/deep_cnn/index.html">CIFAR-10 教程</a>。</p>
<h4>可用的 tensor 有哪些不同的类型？ <a class="md-anchor" id="AUTOGENERATED-what-are-the-different-types-of-tensors-that-are-available-"></a></h4>
<p>TensorFlow 支持许多种不同的数据类型和 tensor shape ，更多细节请参看 <a href="../resources/dims_types.html">ranks, shapes, and type reference</a></p>
<h2 id="9f4e7313a6d8b153f1e4cc768ab252b3">运行 TensorFlow 计算过程。 <a class="md-anchor" id="AUTOGENERATED-running-a-tensorflow-computation"></a></h2>
<p>参看
<a href="../api_docs/python/client.html">运行 graph 的 API 文档</a>.</p>
<h4>请详细解释 feeding 和 placeholders？ <a class="md-anchor" id="AUTOGENERATED-what-s-the-deal-with-feeding-and-placeholders-"></a></h4>
<p>Feeding 是 TensorFlow Session API 的一种机制，它允许你在运行时用不同的值替换一个或多个 tensor 的值。
<a #session.run="" href="../api_docs/python/client.html"><code>Session.run()</code></a> 的参数 <code>feed_dict</code> 是一个字典，
它将 <a href="../api_docs/python/framework.html"><code>Tensor</code></a> 对象映射为 numpy 的数组（和一些其他类型）。
在执行 step 时，这些数组就是 tensor 的值。</p>
<p>你常会碰到某些 tensor 总是有值的，比如 inputs。 <a #placeholder="" href="../api_docs/python/io_ops.html"><code>tf.placeholder()</code></a> 操作(operation)允许你定义一种必须提供值的 tensor ，你也可以随意限定它们的 shape。关于如何使用 placelolders 和 feeding 为神经网络提供训练数据的例子，请参看<a href="../tutorials/mnist/beginners/index.html">初学者的 MNIST 教程</a></p>
<h4><code>Session.run()</code> 和 <code>Tensor.eval()</code> 有什么区别？ <a class="md-anchor" id="AUTOGENERATED-what-is-the-difference-between--session.run----and--tensor.eval----"></a></h4>
<p>如果 <code>t</code> 是一个 <a #tensor="" href="../api_docs/python/framework.html"><code>Tensor</code></a> 对象， <a #tensor.eval="" href="../api_docs/python/framework.html"><code>t.eval()</code></a> 就是 <a #session.run="" href="../api_docs/python/client.html"><code>sess.run(t)</code></a> （<code>sess</code> 是当前<a #get_default_session="" href="../api_docs/python/client.html">默认 session</a>）的简写。
以下两段小程序是等效的：</p>
<pre><code class="language-python"># 使用 `Session.run()`.
sess = tf.Session()
c = tf.constant(5.0)
print sess.run(c)

# 使用 `Tensor.eval()`.
c = tf.constant(5.0)
with tf.Session():
  print c.eval()</code></pre>
<p>在第二个例子中， session 的作用就象 <a "="" href="https://docs.python.org/2.7/reference/compound_stmts.html#with" rel="nofollow">context manager</a> ， context manager 在 <code>with</code> 块的生存期，将 session 作为默认的 session。对简单应用的情形（如单元测试），context manager 的方法可以得到更简洁的代码； 如果你的代码要处理多个 graph 和 session ，更直白的方式可能是显式调用 <code>Session.run()</code>。</p>
<h4>Sessions 有生存期吗？ 调用时产生的 tensors 呢？<a class="md-anchor" id="AUTOGENERATED-do-sessions-have-a-lifetime--what-about-intermediate-tensors-"></a></h4>
<p>Session 能够占有资源，例如 <a #variable="" href="../api_docs/python/state_ops.html">variables</a>，<a #queuebase="" href="../api_docs/python/io_ops.html">queues</a>, 和
<a #readerbase="" href="../api_docs/python/io_ops.html">readers</a>; 这些资源会使用相当大量的内存。 当调用<a #session.close="" href="../api_docs/python/client.html"><code>Session.close()</code></a> 关闭 session 后，这些资源（和相关的内存）就被释放了。</p>
<p>作为调用 <a href="../api_docs/python/client.html"><code>Session.run()</code></a> 过程的一部分所创建的 tensors, 会在调用时或调用结束前释放。</p>
<h4>我可以在多个计算机上运行分布式的训练吗？ <a class="md-anchor" id="AUTOGENERATED-can-i-run-distributed-training-on-multiple-computers-"></a></h4>
<p>最初的 TensorFlow 开源版本支持单一计算机内的多设备（CPUs 和 GPUs）。
我们也正在致力于一个分布式的版本：如果你有兴趣，请告知我们，这样我们可以做相应的调整。</p>
<h4>运行时会并行计算图的执行的各个部分(parts of graph execution)吗？ <a class="md-anchor" id="AUTOGENERATED-does-the-runtime-parallelize-parts-of-graph-execution-"></a></h4>
<p>TensorFlow 运行时会在许多不同的层面(dimensions)并行图的执行(graph execution)：</p>
<ul>
<li>在一个CPU中用多核或是一个GPU中用多线程来并行许多单独的操作(operation)。</li>
<li>在 TensorFlow  graph 中各个独立的节点可以在多个设备上并行，这样就提供了加速的可能。<a href="../tutorials/deep_cnn/index.html">CIFAR-10 用多 GPU 训练</a>.</li>
<li>Session API 允许并行执行多并发的 steps （如 调用 <a #session.run="" href="../api_docs/python/client.html">Session.run()</a>）。
如果单一的 step 不使用你计算机中所有的资源，这种方法可以使运行时有更高的吞吐量。</li>
</ul>
<h4>TensorFlow 支持哪些客户端编程语言？ <a class="md-anchor" id="AUTOGENERATED-which-client-languages-are-supported-in-tensorflow-"></a></h4>
<p>TensorFlow 被设计成为支持多种客户端语言。当前支持最好的客户端语言是 <a href="../api_docs/python/index.html">Python</a>。 <a href="../api_docs/cc/index.html">C++ 客户端 API</a> 提供了启动 graph 和运行 steps 的接口； 我们还有一个 <a "="" href="https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/cc/tutorials/example_trainer.cc" rel="nofollow">用 C++ 建立 graph 的 API</a>，此 API 是实验性的。</p>
<p>从社区的利益出发，我们想要支持更多的客户端语言。 TensorFlow 有一个 <a "="" href="https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/core/public/tensor_c_api.h" rel="nofollow">基于 C 的客户端 API</a>，它使得用许多不同的语言创建客户端变得很容易。我们请大家在新语言绑定上做出努力。</p>
<h4>TensorFlow 会利用我计算机上所有可用的设备（GPUs 和 CPUs）吗？ <a class="md-anchor" id="AUTOGENERATED-does-tensorflow-make-use-of-all-the-devices--gpus-and-cpus--available-on-my-machine-"></a></h4>
<p>TensorFlow 支持多 GPU 和 CPU。 有关 TensorFlow 如何将操作(operations)分配到设备的细节请参看 <a href="../how_tos/using_gpu/index.html">TensorFlow 如何使用 GPUs</a> 的文档，有关使用多 GPU 的示范实例请参看 <a href="../tutorials/deep_cnn/index.html">CIFAR-10 教程</a></p>
<p>请注意， TensorFlow 只使用计算能力(compute capability)大于 3.5 的 GPU 设备。</p>
<h4>当使用一个 reader 或 一个 queue 时，为什么 <code>Session.run()</code> 会挂起？ <a class="md-anchor" id="AUTOGENERATED-why-does--session.run----hang-when-using-a-reader-or-a-queue-"></a></h4>
<p><a #readerbase="" href="../api_docs/python/io_ops.html">reader</a> 类和 <a #queuebase="" href="../api_docs/python/io_ops.html">queue</a> 类提供特殊的操作(operations)，这些操作(operations)在有可用的输入(对有界队列则是空闲空间)前会 <em>阻塞</em> 。使用这些操作(operations)你可以创建复杂的<a href="../how_tos/reading_data/index.html">输入流水线(input pipelines)</a> ,不过，这会使 TensorFlow 的计算过程更复杂。有关如何使用这些操作(operations)的更多信息请参看 how-to 文档中的<a #queuerunners="" href="../how_tos/reading_data/index.html">使用 <code>QueueRunner</code> 对象来控制 queues 和 readers</a>。</p>
<h2 id="94e0ee2b1808b8d3b50ef0d1916d0f73">Variables <a class="md-anchor" id="AUTOGENERATED-variables"></a></h2>
<p>参看 <a href="../how_tos/variables/index.html">Variables</a>
和 <a href="../how_tos/variable_scope/index.html">变量作用域</a> 的 how-to 文档，还有<a href="../api_docs/python/state_ops.html">关于变量的 API 文档</a></p>
<h4>变量的生存期是？ <a class="md-anchor" id="AUTOGENERATED-what-is-the-lifetime-of-a-variable-"></a></h4>
<p>在某一 session 中，当你一开始运行 <a #variable.initializer="" href="../api_docs/python/state_ops.html"><code>tf.Variable.initializer</code></a> 操作(operation)时，变量就会被创建。此 <a #session.close="" href="../api_docs/python/client.html"><code>session 关闭后</code></a>它就被摧毁(destroyed)了。</p>
<h4>并发读取或存入变量时会是什么情况？ <a class="md-anchor" id="AUTOGENERATED-how-do-variables-behave-when-they-are-concurrently-accessed-"></a></h4>
<p>变量可以进行并发的读和写操作(operation)。由于变量是并发(concurrently)更新的， 所以从一个变量中读出的值可能会改变。在不互斥的条件下，对一个变量的并发的许多赋值操作(operation)是默认允许运行的。在对一个变量赋值时，如果想要加锁，可以将 <code>use_locking=True</code> 传递给 <a #variable.assign="" href="../api_docs/python/state_ops.html"><code>Variable.assign()</code></a>。</p>
<h2 id="d74e30c52acf5ce99fc366e0fd8a3690">Tensor shapes <a class="md-anchor" id="AUTOGENERATED-tensor-shapes"></a></h2>
<p>参看
<a #tensorshape="" href="../api_docs/python/framework.html"><code>TensorShape</code> API 文档</a>.</p>
<h4>在 Python 中我怎么判断一个 tensor 的 shape ？ <a class="md-anchor" id="AUTOGENERATED-how-can-i-determine-the-shape-of-a-tensor-in-python-"></a></h4>
<p>在 TensorFlow 中，一个 tensor 具备静态和动态两种 shape 。静态的 shape 可以用 <a #tensor.get_shape="" href="../api_docs/python/framework.html"><code>tf.Tensor.get_shape()</code></a> 方法读出：这种 shape 是由此 tensor 在创建时使用的操作(operations)推导得出的，可能是 <a #tensorshape="" href="../api_docs/python/framework.html">partially complete</a> 的。如果静态 shape 没有完整定义(not fully defined)的话，则一个 tensor 的动态 shape 可通过求 <a #shape="" href="../api_docs/python/array_ops.html"><code>tf.shape(t)</code></a> 的值得到。</p>
<h4><code>x.set_shape()</code> 和 <code>x = tf.reshape(x)</code> 有什么区别？ <a class="md-anchor" id="AUTOGENERATED-what-is-the-difference-between--x.set_shape----and--x---tf.reshape-x---"></a></h4>
<p><a href="../api_docs/python/framework.html"><code>tf.Tensor.set_shape()</code></a> 方法(method)会更新(updates)一个 <code>Tensor</code> 对象的静态 shape ，当静态 shape 信息不能够直接推导得出的时候，此方法常用来提供额外的 shape 信息。它不改变此 tensor 动态 shape 的信息。</p>
<p><a #reshape="" href="../api_docs/python/array_ops.html"><code>tf.reshape()</code></a> 操作(operation)会以不同的动态 shape 创建一个新的 tensor。</p>
<h4>我怎么创建这样一个 graph ，它在批次大小可变(variable batch sizes)的情形下也可以正常运作？ <a class="md-anchor" id="AUTOGENERATED-how-do-i-build-a-graph-that-works-with-variable-batch-sizes-"></a></h4>
<p>如果能够创建一个 graph ，在批次大小可变(variable batch sizes)的情形下也可以正常运作将会是十分有用的，例如可以使用相同的代码完成（小）批量训练((mini-)batch training)和单例推导(single-instance inference)。这样生成的 graph 可以<a #graph.as_graph_def="" href="../api_docs/python/framework.html">保存起来当作协议缓存(protocol buffer)</a>，也可以<a #import_graph_def="" href="../api_docs/python/framework.html">导入至其他的程序</a>。</p>
<p>创建一个可变大小的 graph 时，要记住最重要的事情是不要将批次大小(batch size)编码成为 Python 常数，而是用一个字符性(symbolic)的 <code>Tensor</code> 来表示。下面的提示可能会有用：</p>
<ul>
<li>
<p>用 <a #shape="" href="../api_docs/python/array_ops.html"><code>batch_size = tf.shape(input)[0]</code></a> 从一个叫 <code>input</code> 的 <code>Tensor</code> 提取批次的维度(batch dimention)，再将其存入一个名为 <code>batch_size</code> 的 <code>Tensor</code> 。</p>
</li>
<li>
<p>用 <a #reduce_mean="" href="../api_docs/python/math_ops.html"><code>tf.reduce_mean()</code></a> 而不是 <code>tf.reduce_sum(...) / batch_size</code>。</p>
</li>
<li>如果你使用 <a #feeding="" href="../how_tos/reading_data/index.html">placeholders for feeding input</a>，你就可以用 <a #placeholder="" href="../api_docs/python/io_ops.html"><code>tf.placeholder(..., shape=[None, ...])</code></a> 通过创建 placeholder 来具体指定一个可变的批次维度(variable batch dimention)。shape 的 <code>None</code> 元素与可变大小的维度(a variable-sized dimension)相对应。</li>
</ul>
<h2 id="7bb8d0bb1d13190063e96f13d8010caa">TensorBoard <a class="md-anchor" id="AUTOGENERATED-tensorboard"></a></h2>
<h4>我怎样视觉化一个 TensorFlow graph ？ <a class="md-anchor" id="AUTOGENERATED-how-can-i-visualize-a-tensorflow-graph-"></a></h4>
<p>参看<a href="../how_tos/graph_viz/index.html"> graph 的视觉化教程</a>.</p>
<h4>向 TensorBoard 发送数据的最简单的方法是什么？ <a class="md-anchor" id="AUTOGENERATED-what-is-the-simplest-way-to-send-data-to-tensorboard-"></a></h4>
<p>给你的 TensorFlow  graph 增加 summary 操作(ops)，接着用 <a #summarywriter="" href="../api_docs/python/train.html"><code>SummaryWriter</code></a> 将这些 summaries 写入一个 log directory。然后用以下命令启动 TensorBoard 。</p>
<pre><code>`python tensorflow/tensorboard/tensorboard.py --logdir=path/to/log-directory`</code></pre>
<p>更多细节请参看 <a href="../how_tos/summaries_and_tensorboard/index.html">Summaries 和 TensorBoard 教程</a>。</p>
<h2 id="d5718b5daafedff7a01cfc3e91c0030d">扩展 TensorFlow <a class="md-anchor" id="AUTOGENERATED-extending-tensorflow"></a></h2>
<p>参看有关<a href="../how_tos/adding_an_op/index.html">向 TensorFlow 添加新操作(oprations)</a> 的 how-to 文档。</p>
<h4>我的数据是自定义格式，要怎样用 TensorFlow 来读取它？ <a class="md-anchor" id="AUTOGENERATED-my-data-is-in-a-custom-format.-how-do-i-read-it-using-tensorflow-"></a></h4>
<p>有两种主要的操作(operation)来处理自定义格式的数据。</p>
<p>较简单的方法：用 Python 编写一段分词的代码(parsing code)，将数据转换成为 numpy array，然后用此数据把一个 [<code>tf.placeholder()</code>]
(../api_docs/python/io_ops.md#placeholder) 传送给一个 tensor 。更多的细节参见 <a #feeding="" href="../how_tos/reading_data/index.html">使用 placeholders 进行输入</a> 的相关文档。这个方法比较容易实现，不过分词的部分会成为性能的瓶颈。</p>
<p>更高效的方法是<a href="../how_tos/adding_an_op/index.html">添加一个用 C++ 编写的操作(op)</a>，用这个操作(operation)来对你的数据格式进行分词(parse)。
<a href="../how_tos/new_data_formats/index.html">新数据格式处理指南</a>中有更多相关步骤的信息。</p>
<h4>我如何定义操作(operation)使得它能够接受可变数量的输入？ <a class="md-anchor" id="AUTOGENERATED-how-do-i-define-an-operation-that-takes-a-variable-number-of-inputs-"></a></h4>
<p>TensorFlow 的操作(operation)注册机制允许你定义几种输入：单独的 tensor，一列相同类型的 tensors (例如把一个可变长列表中的 tensors 相加)， 一列不同类型的 tensors (例如将一个 tuple 中的 tensors 入队(enqueue))。有关怎样定义这些不同的输入类型的更多细节，请参看<a #list-input-output="" href="../how_tos/adding_an_op/index.html">添加具有一列输入或输出的操作(op)</a>的相关文档。</p>
<h2 id="e91d15d9dfa3d87d9db98dcfcd67bb78">其他问题 <a class="md-anchor" id="AUTOGENERATED-miscellaneous"></a></h2>
<h4>TensorFlow 能使用 Python 3 吗？ <a class="md-anchor" id="AUTOGENERATED-does-tensorflow-work-with-python-3-"></a></h4>
<p>我们只用 Python 2.7 进行了测试。我们了解对 Python 3 的兼容性来说，还需要有一些修改，欢迎大家朝这个方向多努力。</p>
<h4>TensorFlow 的代码风格有什么规则？ <a class="md-anchor" id="AUTOGENERATED-what-is-tensorflow-s-coding-style-convention-"></a></h4>
<p>TensorFlow Python API 遵循 <a "="" href="https://www.python.org/dev/peps/pep-0008/" rel="nofollow">PEP8</a> 惯例。
<sup>*</sup> 特别的，我们使用 <code>CamelCase</code> 格式作为类名， <code>snake_case</code> 格式作为方程名， 方法名， 和属性名。我们也遵循
<a "="" href="https://google.github.io/styleguide/pyguide.html" rel="nofollow">Google Python style guide</a>。</p>
<p>TensorFlow C++ 代码遵循 <a "="" href="http://google.github.io/styleguide/cppguide.html" rel="nofollow">Google C++ style guide</a>。</p>
<p>(<sup>*</sup> 有一条例外: 我们使用 2 空格缩进而不是 4 空格缩进)</p>
<p>原文：<a "="" href="http://tensorflow.org/resources/faq.md" rel="nofollow">Frequently Asked Questions</a> 翻译：<a "="" href="https://github.com/TerenceCooper" rel="nofollow">Terence Cooper</a> 校对：<a "="" href="https://github.com/jikexueyuanwiki" rel="nofollow">Wiki</a></p>
</div>
    </body></html>